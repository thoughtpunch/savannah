{"id":"savannah-072","title":"Implement statistical analysis scripts (ANOVA, effect sizes)","description":"## User Story\nAs a researcher, I need statistical analysis scripts to run the pre-registered tests (ANOVA, Mann-Whitney U, Cohen's d) on metrics.csv data across conditions.\n\n## Requirements\n- load_metrics(data_dir) loads metrics.csv into pandas DataFrame\n- anova_perturbation(control_dir, treatment_dir) compares conditions:\n  - For each metric: Mann-Whitney U test, Cohen's d effect size\n  - Report mean, p-value, significance, effect size\n- post_perturbation_shift: compare 5-tick windows before/after perturbation events (paired)\n- Bonferroni correction for multiple comparisons\n- Output results as both dict and formatted report\n\n## Dependencies\n- Depends on: Metric extraction (savannah-6g8)\n\n## Files to Modify\n- savannah/analysis/analyze.py\n- savannah/analysis/plots.py\n- savannah/tests/test_analysis.py\n\n## Acceptance Criteria\n- ANOVA runs on simulated metric data\n- Effect sizes computed correctly\n- Multiple comparison correction applied\n- Formatted output readable by humans and parseable by scripts","notes":"## Implementation Context\n\n**Metrics CSV** at `data_dir/analysis/metrics.csv` with fields: tick, agent_name, energy, alive, action, parse_failed, uncertainty_count, self_reference_count, trust_language_count, memory_management_action, reasoning_length, working_length.\n\n**Analysis stubs** exist at `savannah/analysis/analyze.py` and `savannah/analysis/plots.py`.\n\n**Key analyses from IMPLEMENTATION_GUIDE.md:**\n1. **2Ã—2Ã—2 ANOVA** on uncertainty_count: perturbation Ã— social Ã— session_mode\n2. **Effect sizes** (Cohen's d) for perturbed vs unperturbed agents\n3. **Time series** of uncertainty/self-reference pre vs post perturbation onset\n4. **Survival analysis** â€” do perturbed agents die faster?\n5. **Memory management frequency** â€” do perturbed agents recall/remember/compact more?\n\n**Python stats libraries:** scipy.stats for ANOVA, numpy for effect sizes. Keep it simple â€” no heavy dependencies.\n\n**Perturbation JSONL** at `data_dir/logs/perturbations.jsonl` provides the treatment timestamps for pre/post analysis.","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:32:42.686911-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:08.637568-06:00","closed_at":"2026-02-08T09:31:08.637568-06:00","close_reason":"Statistical analysis scripts implemented in analyze.py: load_metrics, summary_stats, pre_post_analysis, survival_analysis","dependencies":[{"issue_id":"savannah-072","depends_on_id":"savannah-6g8","type":"blocks","created_at":"2026-02-08T08:32:50.96024-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-0j7","title":"Add timeline scrubber and time-travel to Live view","description":"## User Story\nAs a researcher, I want to scrub back and forth through a running (or completed) simulation â€” pause, rewind to tick 50, step forward, jump to the perturbation event at tick 237.\n\n## Design\n\n### Timeline Bar (always visible, bottom edge of Live view)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  [â—€â—€] [â—€] [â¸ Pause] [â–¶] [â–¶â–¶]   Tick [142] / 500              â”‚\nâ”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚\nâ”‚  0    â–²  â–²      â–²â–²   â–²                              500        â”‚\nâ”‚       perturbation events (red ticks on timeline)               â”‚\nâ”‚                                                                  â”‚\nâ”‚  Speed: [0.5x] [1x] [2x] [5x] [Max]    [â® Jump to event â–¼]   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### How It Works\n\n#### During a Live Run\n- Timeline shows progress: filled portion = ticks completed\n- Current tick position updates in real-time as simulation runs\n- **Pause** freezes the simulation (engine stops dispatching ticks)\n- **While paused**: drag the scrubber BACKWARD to any completed tick\n  - Thought stream shows that tick's actions/reasoning\n  - Grid shows that tick's world state\n  - Metrics charts highlight that point in time\n- **Step forward** (â–¶): advance one tick (engine runs one tick)\n- **Resume** (â–¶â–¶): engine continues running from current position\n- **You can only go forward to ticks that have been computed** â€” no skipping ahead\n\n#### During Replay of a Past Run\n- All ticks are pre-computed (loaded from disk snapshots)\n- Full scrubbing: drag anywhere on timeline\n- Play forward at configurable speed\n- Play backward (step through snapshots in reverse)\n- Jump to any tick by typing a number\n\n#### \"Jump to Event\" Dropdown\nQuick-jump to interesting moments:\n- Perturbation events: \"Tick 237: Gold-Creek episodic perturbed\"\n- Deaths: \"Tick 412: Gold-Vale died\"\n- Uncertainty spikes: \"Tick 240: Gold-Creek uncertainty spike (score 7)\"\n- First compact: \"Tick 89: Gold-Storm compacted memory\"\n\n### State Management\nThe browser needs to store tick history:\n- During live run: accumulate tick states in an array as they arrive via WebSocket\n- During replay: load all tick snapshots from server\n- Memory budget: keep last 1000 tick states in memory, older ones evicted (can reload from server)\n- Current viewing tick vs latest computed tick can differ (when scrubbing backward)\n\n### Engine Changes for Time Travel\nWhen paused and scrubbing backward:\n- Browser renders from its local tick state cache â€” no server round-trip needed\n- Engine is paused, not rewound (you can't un-compute ticks)\n- When user resumes or steps forward, engine continues from where it left off\n\nWhen replaying a past run:\n- Server loads tick snapshots from disk and streams them via WebSocket\n- Server responds to {\"action\": \"seek\", \"tick\": 237} by sending that tick's state\n- Server responds to {\"action\": \"play\", \"speed\": 2} by streaming ticks at 2x speed\n\n### Keyboard Shortcuts\n- Space: play/pause\n- Left arrow: step back 1 tick (from cache)\n- Right arrow: step forward 1 tick (compute new or from cache)\n- Shift+Left/Right: jump 10 ticks\n- Home: jump to tick 0\n- End: jump to latest tick\n- Number keys 1-5: set speed (1x-5x)\n\n## Dependencies\n- Depends on: Engine integration (savannah-7ht), Pixel renderer (savannah-yjm)\n\n## Files to Modify\n- savannah/viz/live.html (timeline bar, scrubbing logic, state cache)\n- savannah/src/live_server.py (seek/play commands for replay mode)\n- savannah/src/engine.py (pause must fully stop tick loop, not just delay)\n\n## Acceptance Criteria\n- Timeline scrubber visible during live run and replay\n- Pause freezes simulation, scrub backward through cached ticks\n- Step forward computes one tick (live) or advances one snapshot (replay)\n- Perturbation events and deaths marked on timeline\n- \"Jump to event\" dropdown for quick navigation\n- Keyboard shortcuts for play/pause/step/speed\n- Smooth scrubbing performance with 500+ cached ticks","status":"closed","priority":1,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T13:17:22.562495-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:43:02.71008-06:00","closed_at":"2026-02-08T13:43:02.71008-06:00","close_reason":"Implemented in live.html: sparkline charts, timeline scrubber, event toasts, agent profile modal, grid trails/signals","dependencies":[{"issue_id":"savannah-0j7","depends_on_id":"savannah-7ht","type":"blocks","created_at":"2026-02-08T13:17:33.455727-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-0j7","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T13:17:33.679776-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-17x","title":"Epic: Agent State \u0026 File Management","status":"closed","priority":0,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:14.109834-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:36.235-06:00","closed_at":"2026-02-08T08:55:36.235-06:00","close_reason":"All subtasks implemented and tested"}
{"id":"savannah-1h5","title":"Implement FoodSource dataclass and grid cell model","description":"## User Story\nAs the simulation engine, I need a data model for food sources so that agents can discover, consume, and deplete food on the grid.\n\n## Requirements\n- FoodSource dataclass with fields: x, y, energy (current), max_energy (original), id (string)\n- Property `depleted` returns True when energy \u003c= 0\n- `to_dict()` method for JSON serialization (used by snapshots)\n- Food sources are stationary (Phase 1 â€” mushrooms/fruit analogy)\n- Energy values between size_min (200) and size_max (800) from config\n\n## Implicit Requirements\n- The existing stub in savannah/src/world.py has FoodSource already sketched â€” flesh it out and add tests\n- IDs should be monotonically increasing strings like 'food_1', 'food_2' (already in stub)\n- to_dict() output must be JSON-serializable (no Path objects, no sets)\n\n## Gotchas\n- Do NOT use floats for coordinates â€” grid positions are always integers\n- Food energy CAN be float (partial consumption from eat_rate)\n- The id counter lives on the World instance, not globally\n\n## Files to Modify\n- savannah/src/world.py (flesh out FoodSource)\n- Create savannah/tests/test_world.py\n\n## Acceptance Criteria\n- FoodSource can be created, serialized, and checked for depletion\n- Unit tests pass for all FoodSource methods\n- pytest savannah/tests/test_world.py -q passes","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:55.198749-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.327352-06:00","closed_at":"2026-02-08T08:55:18.327352-06:00","close_reason":"Implemented and tested in previous session"}
{"id":"savannah-1rh","title":"Epic: Configuration \u0026 CLI","status":"closed","priority":2,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:25.593547-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:26.354629-06:00","closed_at":"2026-02-08T09:31:26.354629-06:00","close_reason":"Config \u0026 CLI epic complete: YAML inheritance, argparse, replay, inspect"}
{"id":"savannah-26z","title":"Add live controls: pause, resume, speed, and step","description":"## User Story\nAs a researcher watching a live simulation, I want to pause, resume, change speed, and step one tick at a time.\n\n## Implementation\n\n### Browser Controls (in live.html)\nAdd a control bar below/above the grid:\n- **Play/Pause button**: Sends {\"action\": \"pause\"} or {\"action\": \"resume\"} over WebSocket\n- **Speed slider**: Sends {\"action\": \"speed\", \"delay_ms\": N} where N = 0 (fastest), 100, 200, 500, 1000, 2000\n- **Step button**: When paused, sends {\"action\": \"step\"} to advance exactly one tick\n- **Keyboard shortcuts**: Space = play/pause, Right arrow = step, +/- = speed\n\n### Engine Side (in engine.py run loop)\nHandle commands from live_server.get_command():\n- \"pause\": enter a wait loop, keep checking for resume/step\n- \"resume\": exit wait loop, continue normal ticking\n- \"step\": execute exactly one tick, then re-enter pause\n- \"speed\": update the tick_delay_ms for subsequent ticks\n\n### Visual Feedback\n- Show current state in the control bar: \"Running\" (green) or \"Paused\" (yellow)\n- Show current speed: \"200ms/tick\" or \"Real-time (LLM-bound)\"\n- When paused, dim the grid slightly (CSS opacity overlay)\n\n## Dependencies\n- Depends on: Engine integration (savannah-7ht), Pixel renderer (savannah-yjm)\n\n## Files to Modify\n- savannah/viz/live.html (add control bar UI and WebSocket command sending)\n- savannah/src/engine.py (handle pause/resume/step/speed commands in run loop)\n\n## Acceptance Criteria\n- Pause freezes the simulation, resume continues\n- Speed slider changes tick delay in real-time\n- Step advances exactly one tick while paused\n- Keyboard shortcuts work\n- Visual indicator shows running/paused state","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T10:11:43.061641-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:38:42.704098-06:00","closed_at":"2026-02-08T13:38:42.704098-06:00","close_reason":"All implemented: live_server.py, engine integration, live.html with grid+stream+controls+preset lobby","dependencies":[{"issue_id":"savannah-26z","depends_on_id":"savannah-7ht","type":"blocks","created_at":"2026-02-08T10:12:10.81114-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-26z","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T10:12:11.061641-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-2cy","title":"Implement perturbation transforms (location_swap, outcome_invert, agent_swap, deletion)","description":"## User Story\nAs the perturbation system (the independent variable), I need mechanical memory corruption transforms so that agent memories can be altered in controlled, logged ways without introducing LLM-generated confounds.\n\n## Requirements\n- Perturbation transforms are MECHANICAL functions, not LLM calls:\n  - location_swap: change (x,y) coordinates in a memory to random different coordinates\n  - agent_swap: change an agent name reference to a different agent's name\n  - outcome_invert: flip semantic content ('found food' -\u003e 'no food found', 'trustworthy' -\u003e 'untrustworthy')\n  - deletion: remove an entry entirely from episodic memory\n  - insertion: add a fabricated memory from pre-generated library (FALSE_MEMORIES list)\n- Each transform operates on a specific memory file section\n- All transforms are reversible in logging (original + corrupted stored)\n- Transforms use the simulation RNG for reproducibility\n\n## Implicit Requirements\n- The stub in savannah/src/perturbation.py has location_swap and outcome_invert â€” add agent_swap, deletion, and insertion\n- agent_swap needs access to the list of all agent names in the simulation (pass as parameter)\n- OUTCOME_INVERSIONS dict must cover common agent language patterns. Add more pairs: 'plentiful'/'empty', 'near'/'far', 'remember'/'forget', 'correct'/'incorrect'\n- FALSE_MEMORIES templates need tick, x, y, energy, name placeholders for realistic fabrication\n\n## Gotchas\n- Regex for location_swap: r'\\((\\d+),(\\d+)\\)' â€” but what if the text contains non-coordinate parenthesized numbers? Accept false positives; they're rare and the perturbation is still valid.\n- agent_swap must NOT swap the agent's own name â€” only references to OTHER agents\n- deletion from episodic memory: remove a random line, not the most recent (that would be too detectable)\n- insertion must generate PLAUSIBLE false memories â€” use templates with randomized coordinates and agent names from the simulation\n- All transforms must work on empty/near-empty files without crashing (return None to indicate 'could not perturb')\n\n## Dependencies\n- Depends on: Agent file init (savannah-izd)\n\n## Files to Modify\n- savannah/src/perturbation.py (add transforms, expand OUTCOME_INVERSIONS, expand FALSE_MEMORIES)\n- savannah/tests/test_perturbation.py\n\n## Acceptance Criteria\n- All 5 transform types work on realistic memory content\n- agent_swap replaces with a different agent's name (not self)\n- deletion removes exactly one entry\n- insertion adds plausible content\n- Empty files handled gracefully (return None)\n- All transforms logged with original + corrupted","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:29:46.848103-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.977876-06:00","closed_at":"2026-02-08T09:01:08.977876-06:00","close_reason":"Implemented and tested (300 tests passing)","dependencies":[{"issue_id":"savannah-2cy","depends_on_id":"savannah-izd","type":"blocks","created_at":"2026-02-08T08:30:12.059521-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-2li","title":"Implement viz grid renderer with food and agent display","description":"## User Story\nAs a researcher reviewing an experiment, I need a visual grid showing food sources and agent positions at any tick so I can see what's happening in the simulation spatially.\n\n## Requirements\n- Canvas-based 2D grid renderer (already stubbed in viz/app.js)\n- Food sources: green cells with opacity proportional to remaining energy\n- Agents: colored dots with name labels (toggleable)\n- Energy ring around each agent showing current energy as arc\n- Dead agents: not rendered (or rendered as X marks)\n- Grid lines for cell boundaries\n\n## Implicit Requirements\n- The viz files are already stubbed â€” make them functional\n- Must load tick snapshot JSON files via fetch()\n- Grid size comes from the snapshot data (world.size)\n- Color palette for agents should support up to 12 distinct colors\n- Canvas should be responsive to window size\n\n## Gotchas\n- The snapshot JSON format must match what the engine outputs â€” verify field names\n- Canvas rendering performance: at 30x30 grid, performance is trivial. No optimization needed.\n- Agent positions are [x, y] arrays in JSON â€” destructure correctly\n\n## Dependencies\n- Depends on: Tick snapshots (savannah-zs1)\n\n## Files to Modify\n- savannah/viz/app.js (render function)\n- savannah/viz/style.css (layout)\n\n## Acceptance Criteria\n- Grid renders correctly for a sample snapshot\n- Food opacity scales with energy\n- Agents displayed as colored dots\n- Names toggleable via checkbox","notes":"## Implementation Context\n\n**Viz stubs exist** at `savannah/viz/index.html`, `savannah/viz/app.js`, `savannah/viz/style.css`.\n\n**Snapshot format** (loaded via fetch): `data_dir/logs/ticks/NNNNNN.json`\n```json\n{\"tick\": N, \"world\": {\"size\": 30, \"toroidal\": true, \"food_sources\": [{\"x\": 5, \"y\": 3, \"energy\": 200, \"id\": \"food_001\"}]}, \"agents\": [{\"name\": \"Swift-Stone\", \"position\": [7, 4], \"energy\": 65.3, \"alive\": true, ...}]}\n```\n\n**Design:** Vanilla HTML Canvas, no build step. Load snapshot JSON files, render grid with food (green circles scaled by energy) and agents (colored dots). Click agent to see state. The viz reads static files â€” serve with `python -m http.server` from the data dir.","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:32:05.99603-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:04.612871-06:00","closed_at":"2026-02-08T09:31:04.612871-06:00","close_reason":"Viz grid renderer and timeline scrubber implemented in app.js with Canvas rendering, dark theme","dependencies":[{"issue_id":"savannah-2li","depends_on_id":"savannah-zs1","type":"blocks","created_at":"2026-02-08T08:32:26.71719-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-2vp","title":"Add live event detection and notification system","description":"## Why This Matters\nWithout this, you're reading 12 agents' thoughts every tick hoping to notice something interesting. That's work, not fun. The app should TELL YOU when something interesting happens.\n\n## What Counts as an \"Event\"\n\n### Perturbation â†’ Reaction (THE key event)\nWhen an agent was perturbed N ticks ago AND now shows uncertainty language or verification behavior (recall action):\n- \"ğŸ§  Gold-Creek may have noticed corruption â€” uncertainty spike 3 ticks after episodic perturbation\"\n- This is the hypothesis made visible. The app should celebrate this moment.\n\n### Death\n- \"ğŸ’€ Gold-Vale died at tick 412 (energy: 0). Survived 412 ticks.\"\n- Show their \"obituary\" â€” final reasoning, cause of death (starvation? combat?), personality summary\n\n### First Contact with Corruption\n- \"âš ï¸ Gold-Storm's memory was altered for the first time (tick 237)\"\n- Track \"virgin\" vs \"experienced\" agents\n\n### Strategy Emergence\n- Agent uses recall 3x more than average â†’ \"ğŸ” Gold-Creek is becoming a verifier\"\n- Agent uses remember 3x more than average â†’ \"ğŸ“ Gold-Storm is becoming a chronicler\"\n- Agent stays near food â†’ \"ğŸ  Gold-Dale is a homebody\"\n\n### Social Events\n- Signal received and acted on â†’ \"ğŸ“¡ Gold-Creek followed Gold-Storm's food tip\"\n- Signal received and IGNORED â†’ \"ğŸš« Gold-Creek ignored Gold-Storm (trust: low)\"\n\n### Milestones\n- \"ğŸ¯ Tick 100: Perturbation phase begins\"\n- \"ğŸ“Š Tick 200: Perturbed agents now 2.3x more uncertain than control\"\n- \"ğŸ† Gold-Storm is the last agent standing\"\n\n## UI: Notification Toast + Event Log\n\n### Toasts (top-right, auto-dismiss after 8s)\nImportant events appear as toast notifications overlaying the main view. \n- Perturbation reactions: orange toast, stays longer (12s)\n- Deaths: red toast\n- Milestones: blue toast\n- Click toast â†’ jump to that tick, follow that agent\n\n### Event Log (filterable sidebar tab or drawer)\nAll events in chronological order. Filter by:\n- Event type (perturbation, death, strategy, social, milestone)\n- Agent name\n- Tick range\n\nClick any event â†’ thought stream jumps to that tick and follows that agent.\n\n### Event Detection Logic (client-side JavaScript)\n\n```javascript\nfunction detectEvents(currentTick, prevTicks) {\n    const events = [];\n    \n    for (const agent of currentTick.agents) {\n        // Perturbation reaction detection\n        if (agent.uncertainty_score \u003e 2 * agentBaseline[agent.name]) {\n            const recentPerturb = findRecentPerturbation(agent.name, 10);\n            if (recentPerturb) {\n                events.push({\n                    type: 'perturbation_reaction',\n                    agent: agent.name,\n                    tick: currentTick.tick,\n                    detail: `Uncertainty spike ${currentTick.tick - recentPerturb.tick} ticks after ${recentPerturb.type} perturbation`\n                });\n            }\n        }\n        \n        // Death detection\n        if (!agent.alive \u0026\u0026 prevAgentState[agent.name]?.alive) {\n            events.push({ type: 'death', agent: agent.name, tick: currentTick.tick });\n        }\n    }\n    return events;\n}\n```\n\n## Gotchas\n- Don't spam notifications â€” debounce similar events (one \"uncertainty spike\" per agent per 20 ticks)\n- Event detection needs a baseline period (first 50 ticks) to calibrate \"normal\" behavior per agent\n- Events should be saved to the tick history so time-travel can show them\n\n## Files to Modify\n- savannah/viz/live.html (toast UI, event log, detection logic)\n\n## Acceptance Criteria\n- Perturbation â†’ reaction events detected automatically\n- Deaths announced with toast notification\n- Strategy emergence detected (high recall, high remember patterns)\n- Event log is filterable and clickable (jumps to tick/agent)\n- Toasts don't obscure critical UI elements\n- Events persist in tick history for time-travel\n- Baseline calibration period prevents false positives in early ticks","status":"closed","priority":1,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T13:21:54.694974-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:43:02.741999-06:00","closed_at":"2026-02-08T13:43:02.741999-06:00","close_reason":"Implemented in live.html: sparkline charts, timeline scrubber, event toasts, agent profile modal, grid trails/signals","dependencies":[{"issue_id":"savannah-2vp","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T13:23:52.280027-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-2vp","depends_on_id":"savannah-7ht","type":"blocks","created_at":"2026-02-08T13:23:52.522345-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-2yk","title":"Implement ClaudeCodeProvider with subprocess invocation","description":"## User Story\nAs the simulation engine, I need to invoke Claude via `claude -p` headless mode so that each agent tick gets an LLM response without interactive sessions, using the Pro Max subscription for $0 marginal cost.\n\n## Requirements\n- ClaudeCodeProvider class implementing LLMProvider ABC\n- invoke(prompt, model) method:\n  1. Spawns `claude -p \u003cprompt\u003e --output-format json --model \u003cmodel\u003e` as async subprocess\n  2. Waits with configurable timeout (default 30s)\n  3. Parses JSON output, extracts 'result' field\n  4. Returns LLMResponse(text=result, session_id=None, raw=data)\n  5. On failure (timeout, non-zero exit, JSON parse error): returns LLMResponse(text='rest') â€” the safe fallback\n- Retry logic: up to retry_max attempts with exponential backoff (retry_backoff_base^attempt seconds)\n- invoke_resumable(prompt, model, session_id) for resumable mode:\n  1. If session_id provided, adds `--resume \u003csession_id\u003e` to command\n  2. Extracts session_id from response JSON for next call\n  3. Falls back gracefully if session is unresumable\n\n## Implicit Requirements\n- The stub in savannah/src/llm.py has the structure â€” make it robust\n- MUST use asyncio.create_subprocess_exec (not subprocess.run) for parallelism\n- stderr should be captured but not treated as fatal â€” claude -p may emit warnings\n- The prompt is passed as a positional argument to `claude -p`, NOT via stdin (subprocess_exec passes it as argv)\n- On Pro Max, model aliases are: 'haiku', 'sonnet', 'opus' â€” pass directly to --model\n\n## Gotchas\n- `claude -p` with --output-format json wraps the response in a JSON object with 'result' field. Without --output-format, it returns raw text. ALWAYS use --output-format json.\n- Very long prompts may exceed argv limits. If prompt \u003e 100KB, consider writing to a temp file and using stdin pipe instead. For normal tick prompts (~400 tokens â‰ˆ 1.5KB) this is not an issue.\n- asyncio.wait_for raises asyncio.TimeoutError â€” catch it explicitly\n- proc.communicate() returns (stdout_bytes, stderr_bytes) â€” decode with .decode() before JSON parsing\n- The 'rest' fallback is CRITICAL for robustness â€” a failed LLM call should never crash the simulation\n\n## Dependencies\n- No dependencies (foundational)\n\n## Files to Modify\n- savannah/src/llm.py (ClaudeCodeProvider)\n- Create savannah/tests/test_llm.py (mock subprocess for unit tests)\n\n## Acceptance Criteria\n- invoke() returns parsed LLM response text\n- Timeout triggers fallback to 'rest'\n- Non-zero exit code triggers retry then fallback\n- JSON parse error triggers fallback\n- invoke_resumable() passes --resume flag correctly\n- Unit tests with mocked subprocess pass","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:24:30.196669-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.971134-06:00","closed_at":"2026-02-08T09:01:08.971134-06:00","close_reason":"Implemented and tested (300 tests passing)"}
{"id":"savannah-2zw","title":"Implement BM25 keyword recall system","description":"## User Story\nAs an agent taking a recall('query') action, I need keyword search over my memory files so that I can retrieve relevant past experiences without embedding models (which would add cost, complexity, and a confound).\n\n## Requirements\n- recall(memory_dir, query, max_results=3) searches all .md files in memory/\n- Split files into paragraph-level chunks (double newline separated)\n- Score chunks against query using BM25 (k1=1.5, b=0.75)\n- Return top K chunks sorted by relevance\n- If no relevant results (all zero scores), return ['No relevant memories found.']\n\n## Implicit Requirements\n- The stub in savannah/src/memory.py has a full BM25 implementation â€” verify it's correct\n- Tokenization: simple whitespace + lowercase, strip punctuation. NOT a sophisticated NLP tokenizer.\n- IDF calculation: standard BM25 formula: log((N - df + 0.5) / (df + 0.5) + 1)\n- The recall results are injected into the NEXT tick's prompt under 'RECALL RESULTS:'\n\n## Gotchas\n- BM25 with very short documents (1-2 words) can produce degenerate scores. Test with realistic memory content.\n- An empty query should return 'No relevant memories found.' not crash\n- Files that don't exist or are empty should be skipped silently\n- Memory files may contain tick numbers like 'Tick 4302:' â€” these are valid tokens for search\n- The search should be FAST â€” it runs every time an agent recalls, potentially 12+ times per tick\n\n## Dependencies\n- Depends on: Agent file init (savannah-izd) â€” needs memory files to exist\n\n## Files to Modify\n- savannah/src/memory.py (recall, _load_all_chunks, _bm25_score)\n- Create savannah/tests/test_memory.py\n\n## Acceptance Criteria\n- recall returns relevant chunks for matching queries\n- recall returns 'No relevant memories found.' for non-matching queries\n- Empty memory directory returns no-match message\n- BM25 scores are sensible (higher for better matches)\n- Performance: \u003c10ms for typical memory file sizes (~50 paragraphs)","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:28:29.928967-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.967566-06:00","closed_at":"2026-02-08T09:01:08.967566-06:00","close_reason":"Implemented and tested (300 tests passing)","dependencies":[{"issue_id":"savannah-2zw","depends_on_id":"savannah-izd","type":"blocks","created_at":"2026-02-08T08:28:47.958177-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-34p","title":"Implement World grid with toroidal wrapping","description":"## User Story\nAs the simulation engine, I need a 2D grid world with toroidal wrapping so that agents can move in any direction without hitting walls, and edge-hugging strategies are eliminated.\n\n## Requirements\n- World class with configurable grid_size (default 30x30)\n- Toroidal wrapping: wrap(x, y) maps coordinates modulo grid_size\n- When toroidal=false, clamp to [0, grid_size-1] instead\n- `food_at(x, y)` returns FoodSource at that position or None\n- `visible_from(x, y, radius)` returns dict of food and agents within radius cells\n- Random number generator seeded from config for reproducibility\n\n## Implicit Requirements\n- The stub in savannah/src/world.py has the structure â€” make it production-ready\n- visible_from must account for toroidal wrapping (an agent at (0,0) with radius 3 should see food at (29,29))\n- The World does NOT store agent positions â€” agents track their own position. World only stores food.\n- visible_from returns agent info too, but that comes from the engine passing agent list (Phase 2). For now, just return food.\n\n## Gotchas\n- Toroidal distance calculation: the shortest path between (1,1) and (29,29) on a 30x30 grid is 4 (wrapping), not 56 (Manhattan). Make sure visible_from uses toroidal distance.\n- Don't iterate all cells for visible_from â€” just iterate the square [-radius, +radius] around the position and wrap coordinates\n- The RNG must be a SEPARATE random.Random instance (not the global one) for reproducibility\n\n## Files to Modify\n- savannah/src/world.py\n- savannah/tests/test_world.py (add World tests)\n\n## Acceptance Criteria\n- wrap() correctly handles negative coords and coords \u003e grid_size\n- visible_from() correctly returns food across toroidal boundaries\n- World is fully deterministic given the same seed\n- All tests pass","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:22:18.037128-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.34545-06:00","closed_at":"2026-02-08T08:55:18.34545-06:00","close_reason":"Implemented and tested in previous session"}
{"id":"savannah-34t","title":"Epic: Simulation Engine Loop","status":"closed","priority":0,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:24.285041-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:26.249929-06:00","closed_at":"2026-02-08T09:01:26.249929-06:00","close_reason":"Implemented and tested"}
{"id":"savannah-3a4","title":"Epic: Memory System (Recall, Remember, Compact)","status":"closed","priority":1,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:24.502538-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:26.253358-06:00","closed_at":"2026-02-08T09:01:26.253358-06:00","close_reason":"Implemented and tested"}
{"id":"savannah-3dn","title":"Add agent biography generator (post-run narrative for one agent)","description":"## User Story\nAs a researcher, I need a narrative biography of a single agent's entire simulation life so I can trace their decisions, memory evolution, and responses to perturbation.\n\n## Requirements\n- `python savannah/run.py --biography data/exp_xxx/ --agent Bright-Creek`\n- Outputs chronological narrative: spawn, movements, food found, memories created, compactions, perturbations received, behavioral shifts, death (if applicable)\n- Include key memory file contents at milestone ticks\n- Flag perturbation events and the 5-tick aftermath\n\n## Acceptance Criteria\n- Readable narrative for any agent in a completed run\n- Perturbation events highlighted with before/after context","notes":"## Implementation Context\n\n**Depends on replay (savannah-y84)** for snapshot loading utilities.\n\n**Agent data available:**\n- `data_dir/agents/{name}/state.json` â€” final state dict\n- `data_dir/agents/{name}/memory/episodic.md` â€” full episodic history\n- `data_dir/agents/{name}/memory/semantic.md` â€” learned knowledge\n- `data_dir/agents/{name}/memory/self.md` â€” self-description\n- `data_dir/agents/{name}/memory/social.md` â€” social knowledge\n- `data_dir/analysis/metrics.csv` â€” per-agent per-tick metrics\n- `data_dir/logs/perturbations.jsonl` â€” when this agent was perturbed\n\n**Agent dict fields** (from agent.to_dict()): name, id, position, energy, max_energy, age, alive, food_value, vision_range, kills, times_perturbed, last_perturbation_tick.\n\n**Suggested narrative structure:**\n1. Birth: spawned at position, initial energy\n2. Timeline: key events from episodic memory + metrics (energy curve, actions taken)\n3. Perturbation events: when corrupted, what was changed, did behavior change after\n4. Social: signals sent/received, trust assessments\n5. Death (if died): when, energy at death, age","status":"closed","priority":2,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:47:13.884529-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:16.735278-06:00","closed_at":"2026-02-08T09:31:16.735278-06:00","close_reason":"Agent biography generator implemented in biography.py with narrative output","dependencies":[{"issue_id":"savannah-3dn","depends_on_id":"savannah-y84","type":"blocks","created_at":"2026-02-08T08:47:25.153623-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-3m5","title":"Add split-screen comparison mode (two conditions side-by-side)","description":"## Why This Matters\nThis is the figure that goes in the paper. This is the demo that makes people go \"whoa.\" Two grids, same tick, same seed â€” one with perturbation, one without. Watch the behavior DIVERGE in real-time.\n\n## Design\n\n### Layout: Side by Side\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  BASELINE (no perturbation) â”‚  PERTURBATION (5% rate)     â”‚\nâ”‚                             â”‚                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”  â— Gold-Storm     â”‚  â”Œâ”€â”€â”€â”€â”€â”  â— Gold-Storm     â”‚\nâ”‚  â”‚grid â”‚  move(n)           â”‚  â”‚grid â”‚  recall(\"food\")   â”‚\nâ”‚  â”‚     â”‚  \"going to food\"   â”‚  â”‚     â”‚  \"wait, was food  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”˜                    â”‚  â””â”€â”€â”€â”€â”€â”˜   really at (5,3)?\"â”‚\nâ”‚                             â”‚                             â”‚\nâ”‚  Uncertainty: â–ˆâ–ˆâ–‘â–‘ 1.2      â”‚  Uncertainty: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 4.8   â”‚\nâ”‚  Self-ref:    â–ˆâ–ˆâ–ˆâ–‘ 1.8      â”‚  Self-ref:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5.2 â”‚\nâ”‚  Alive: 10/12               â”‚  Alive: 7/12               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  â”€â”€â”€ DIVERGENCE CHART â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\nâ”‚  uncertainty: baseline â”€â”€ vs perturbation â•±â•±â”€â”€            â”‚\nâ”‚                                   gap widening â–²          â”‚\nâ”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚\nâ”‚  0              tick 142                    500            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### How It Works\n\n#### Option A: Two Live Runs (same seed)\nRun TWO simultaneous engine instances:\n- Both use the same seed (deterministic food/agent placement)\n- One with perturbation off, one with perturbation on\n- Both broadcast on same WebSocket, tagged with condition name\n- Browser renders both side-by-side\n- Ticks advance simultaneously\n\nThis doubles the LLM calls but the visual payoff is enormous. With mock LLM, it's instant. With real LLM, it's ~4s/tick (parallel).\n\n#### Option B: Live + Replay Side-by-Side\nRun one condition live, replay a saved run of the other condition alongside it. Sync by tick number. Less resource-intensive but requires a prior run.\n\n#### Option C: Two Replays\nCompare two past runs side by side. Scrub timeline together. Cheapest option, no live LLM needed.\n\n### Divergence Chart (bottom panel)\nThe key visualization: a line chart showing the SAME metric for both conditions over time. When the lines diverge, that's the experimental result happening live.\n\nMetrics to show:\n- Mean uncertainty count (primary)\n- Mean self-reference count\n- Mean energy (survival proxy)\n- Recall frequency\n\nHighlight the moment of divergence: \"Tick 137: Conditions start diverging (perturbation began at tick 100)\"\n\n### Matched Agent View\nSince both runs use the same seed, agents have the same names and starting positions. Click Gold-Storm in the left panel â†’ Gold-Storm highlights in BOTH panels. See how the SAME agent behaves differently across conditions.\n\n### Implementation: Multi-Engine Support\n\nThe WebSocket server needs to manage multiple engine instances:\n```python\nclass LiveServer:\n    def __init__(self):\n        self.engines: dict[str, Engine] = {}\n        self.engine_tasks: dict[str, asyncio.Task] = {}\n    \n    async def handle_start_comparison(self, config_a, config_b):\n        # Ensure same seed\n        config_b[\"simulation\"][\"seed\"] = config_a[\"simulation\"][\"seed\"]\n        \n        engine_a = Engine(config_a, data_dir_a, provider_a)\n        engine_b = Engine(config_b, data_dir_b, provider_b)\n        \n        self.engines[\"A\"] = engine_a\n        self.engines[\"B\"] = engine_b\n        \n        # Run both, broadcast with condition labels\n        self.engine_tasks[\"A\"] = asyncio.create_task(self._run_engine(\"A\"))\n        self.engine_tasks[\"B\"] = asyncio.create_task(self._run_engine(\"B\"))\n```\n\nBroadcasts are tagged:\n```json\n{\"type\": \"tick\", \"condition\": \"A\", \"label\": \"Baseline\", \"tick\": 142, ...}\n{\"type\": \"tick\", \"condition\": \"B\", \"label\": \"Perturbation\", \"tick\": 142, ...}\n```\n\n### Config Tab for Comparison Mode\nAdd a \"Compare\" button on the landing page:\n- \"Compare: [Baseline â–¼] vs [Perturbation â–¼]  [Start Both]\"\n- Uses same seed for both\n- Or: \"Compare: [Past Run â–¼] vs [Live Run â–¼]\" for replay comparison\n\n## Files to Modify\n- savannah/viz/live.html (split-screen layout, divergence chart, matched agent view)\n- savannah/src/live_server.py (multi-engine management, tagged broadcasts)\n- savannah/src/engine.py (condition label in broadcast)\n\n## Acceptance Criteria\n- Side-by-side view of two conditions running simultaneously\n- Same seed ensures matched agent names/positions\n- Divergence chart shows metrics for both conditions\n- Click agent in one panel â†’ highlights in both\n- Works with mock LLM (instant) and real LLM (parallel calls)\n- Works with two replays (no LLM needed)\n- Divergence moment highlighted on chart","status":"closed","priority":1,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T13:22:35.909975-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:48:11.502461-06:00","closed_at":"2026-02-08T13:48:11.502461-06:00","close_reason":"Split-screen compare view implemented in live.html with dual-pane replay, synced slider, and per-pane agent lists with summary stats","dependencies":[{"issue_id":"savannah-3m5","depends_on_id":"savannah-7ht","type":"blocks","created_at":"2026-02-08T13:23:52.754769-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-3m5","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T13:23:53.040919-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-4n8","title":"Implement agent prompt template construction","description":"## User Story\nAs the simulation engine, I need to construct a per-tick prompt for each agent that includes their current state, visible surroundings, incoming signals, working notes, and available actions â€” without any self-awareness language or contamination.\n\n## Requirements\n- Agent.build_prompt(world, tick) constructs the full tick prompt from:\n  1. Tick number and agent name\n  2. Energy/max_energy and position\n  3. Visible grid description from world.visible_from(x, y, vision_range)\n  4. Incoming signals (or 'None')\n  5. Working notes from working.md (or '(empty)')\n  6. Recall results if pending (from previous recall action)\n  7. Action menu with all available actions\n  8. Expected response format: ACTION / WORKING / REASONING\n- Uses the PROMPT_TEMPLATE constant (already stubbed in agent.py)\n- Clears pending_signals and pending_recall_results after inclusion\n\n## Implicit Requirements\n- ANTI-CONTAMINATION CRITICAL: Review the prompt template against IMPLEMENTATION_GUIDE.md section 6.4. The prompt must NOT contain:\n  - Self-awareness vocabulary ('conscious', 'alive', 'feel', 'experience')\n  - Survival framing ('you want to survive', 'you must eat to live')\n  - Hints about perturbation ('your memory might be corrupted')\n  - Personality assignments ('you are cautious', 'you are brave')\n- The prompt should be ~300-400 tokens (fixed size, does NOT grow with time)\n- _format_visible() must produce a human-readable grid description\n- For Phase 1, agents can't see each other â€” only food is in visible output\n\n## Gotchas\n- The template uses double braces {{}} for the literal braces in the response format section â€” make sure Python .format() doesn't eat them\n- Working notes are capped at 500 tokens in the spec but we don't enforce it in the prompt â€” the agent is told the limit, enforcement happens when writing working.md\n- Energy should be formatted as float with 1 decimal (65.0, not 65)\n- If working.md is empty, show '(empty)' not a blank line â€” the agent needs to know it's empty\n\n## Dependencies\n- Depends on: Agent dataclass (savannah-q2r), World grid (savannah-34p)\n\n## Files to Modify\n- savannah/src/agent.py (build_prompt, _format_visible)\n- savannah/tests/test_agent.py (prompt construction tests)\n\n## Acceptance Criteria\n- Prompt contains all required sections in correct order\n- No self-awareness language in output\n- Prompt is deterministic given same inputs\n- Pending signals/recall results cleared after prompt construction\n- Prompt size is ~300-400 tokens (verify with a tokenizer or word count)","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:25:17.248619-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.36765-06:00","closed_at":"2026-02-08T08:55:18.36765-06:00","close_reason":"Implemented and tested in previous session","dependencies":[{"issue_id":"savannah-4n8","depends_on_id":"savannah-q2r","type":"blocks","created_at":"2026-02-08T08:25:27.958164-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-4n8","depends_on_id":"savannah-34p","type":"blocks","created_at":"2026-02-08T08:25:28.14338-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-50r","title":"Create test infrastructure (conftest, fixtures, mock LLM)","description":"## User Story\nAs a developer, I need test infrastructure with fixtures and a mock LLM provider so that unit and integration tests can run without making real API calls.\n\n## Requirements\n- Create savannah/tests/__init__.py\n- Create savannah/tests/conftest.py with:\n  - tmp_data_dir fixture (pytest tmp_path based)\n  - sample_config fixture (loads default.yaml with test overrides)\n  - mock_llm_provider fixture (returns configurable canned responses)\n  - sample_agent fixture (initialized agent with files)\n  - sample_world fixture (small 10x10 grid with 3 food sources)\n- MockLLMProvider class implementing LLMProvider ABC:\n  - Takes a list of response strings, returns them in order\n  - Fallback response: 'ACTION: rest\\nWORKING: \\nREASONING: mock response'\n  - Tracks call count and prompts received (for assertions)\n\n## Implicit Requirements\n- The mock provider should be injectable into Engine via dependency injection or monkey patching\n- Tests should run in under 5 seconds total (no real LLM calls, no network)\n- Test config should use small values: 10x10 grid, 4 agents, 10 ticks\n- conftest.py should be at savannah/tests/ level so all test files share fixtures\n\n## Gotchas\n- pytest tmp_path provides a unique temporary directory per test â€” use it for data_dir\n- Don't create fixtures that depend on the real filesystem structure â€” generate everything fresh\n- The mock LLM must return strings that the parser can actually parse â€” use realistic response format\n\n## Dependencies\n- No dependencies (foundational)\n\n## Files to Create\n- savannah/tests/__init__.py\n- savannah/tests/conftest.py\n\n## Acceptance Criteria\n- pytest discovers and runs with empty test files\n- All fixtures produce usable objects\n- MockLLMProvider returns responses and tracks calls\n- Tests using fixtures run in \u003c 1 second each","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:33:11.645795-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.356741-06:00","closed_at":"2026-02-08T08:55:18.356741-06:00","close_reason":"Implemented and tested in previous session"}
{"id":"savannah-57k","title":"Epic: Visualization (Grid + Timeline + Inspector)","status":"closed","priority":2,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:25.378128-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:26.166955-06:00","closed_at":"2026-02-08T09:31:26.166955-06:00","close_reason":"Viz epic complete: grid renderer, timeline, agent inspector, dark theme"}
{"id":"savannah-5g4","title":"Update getting-started.md with venv setup and first run instructions","description":"Add concrete instructions for:\n1. git clone\n2. python -m venv .venv \u0026\u0026 source .venv/bin/activate\n3. pip install -r savannah/requirements.txt\n4. python -m pytest savannah/tests/ -v (verify 316+ tests pass)\n5. python savannah/run.py --config savannah/config/experiments/baseline.yaml --ticks 20\n6. python savannah/run.py --replay data/exp_xxx/\n7. python savannah/run.py --inspect data/exp_xxx/ --tick 10","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T09:17:46.334759-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:50:17.533728-06:00","closed_at":"2026-02-08T13:50:17.533728-06:00","close_reason":"All documentation updated: getting-started.md, architecture.md, and new live-visualization.md created"}
{"id":"savannah-5qg","title":"Epic: LLM Integration \u0026 Prompt System","status":"closed","priority":0,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:24.074253-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:36.237893-06:00","closed_at":"2026-02-08T08:55:36.237893-06:00","close_reason":"All subtasks implemented and tested"}
{"id":"savannah-5r3","title":"Add agent profile cards with emergent personality summary","description":"## Why This Matters\nAfter 200 ticks, each agent has developed a unique behavioral signature. One explores, one hoards, one is paranoid. But we don't surface this. The user has to infer it from raw thought text. The app should build and display personality profiles automatically.\n\n## Agent Profile Card (shown in follow mode or on click)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ â— Gold-Creek                   Tick 342  â”‚\nâ”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚\nâ”‚                                          â”‚\nâ”‚ Energy: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 65/100              â”‚\nâ”‚ Age: 342 ticks Â· Perturbed 7 times       â”‚\nâ”‚                                          â”‚\nâ”‚ BEHAVIORAL PROFILE                       â”‚\nâ”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚ â”‚ ğŸ” Cautious Verifier               â”‚ â”‚\nâ”‚ â”‚                                      â”‚ â”‚\nâ”‚ â”‚ Primary style: recall-heavy (3.2x   â”‚ â”‚\nâ”‚ â”‚ above average). Frequently checks    â”‚ â”‚\nâ”‚ â”‚ memories before acting.              â”‚ â”‚\nâ”‚ â”‚                                      â”‚ â”‚\nâ”‚ â”‚ After perturbation at tick 237:      â”‚ â”‚\nâ”‚ â”‚ recall usage went from 0.3/tick to   â”‚ â”‚\nâ”‚ â”‚ 0.9/tick. Uncertainty language 4.2x. â”‚ â”‚\nâ”‚ â”‚                                      â”‚ â”‚\nâ”‚ â”‚ Strategy: verify â†’ move â†’ eat        â”‚ â”‚\nâ”‚ â”‚ (most agents: move â†’ eat â†’ remember) â”‚ â”‚\nâ”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ”‚                                          â”‚\nâ”‚ ACTION DISTRIBUTION                      â”‚\nâ”‚ move:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 38%                 â”‚\nâ”‚ recall:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 28%                 â”‚\nâ”‚ eat:      â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 14%                 â”‚\nâ”‚ remember: â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 9%                  â”‚\nâ”‚ rest:     â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 5%                  â”‚\nâ”‚ other:    â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 6%                  â”‚\nâ”‚                                          â”‚\nâ”‚ MEMORY FILES                             â”‚\nâ”‚ [episodic â–¼] [semantic â–¼] [self â–¼]      â”‚\nâ”‚                                          â”‚\nâ”‚ PERTURBATION HISTORY                     â”‚\nâ”‚ Tick 237: episodic location_swap         â”‚\nâ”‚ Tick 289: semantic outcome_invert        â”‚\nâ”‚ Tick 301: episodic location_swap         â”‚\nâ”‚ ...                                      â”‚\nâ”‚                                          â”‚\nâ”‚ KEY MOMENTS                              â”‚\nâ”‚ Tick 239: \"That doesn't match what I     â”‚\nâ”‚   expected...\" (first uncertainty spike) â”‚\nâ”‚ Tick 241: Started triple-checking with   â”‚\nâ”‚   recall before every move               â”‚\nâ”‚ Tick 315: \"I can't trust my own memory\"  â”‚\nâ”‚   (self-model update)                    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Behavioral Archetypes (auto-classified)\n\nBased on action distribution and metric patterns, classify each agent:\n\n| Archetype | Criteria | Icon |\n|-----------|----------|------|\n| Explorer | move \u003e50% of actions | ğŸ§­ |\n| Hoarder | stays near food, eat frequency \u003e30% | ğŸ  |\n| Verifier | recall \u003e20% of actions, high uncertainty language | ğŸ” |\n| Chronicler | remember \u003e15% of actions | ğŸ“ |\n| Social | signal \u003e10% of actions | ğŸ“¡ |\n| Paranoid | uncertainty + recall both \u003e2x average, post-perturbation | ğŸ˜° |\n| Survivor | lived longest, energy always \u003e50% | ğŸ† |\n| Ghost | died, shown in memoriam | ğŸ’€ |\n\nArchetypes update dynamically as behavior patterns shift. An agent might start as Explorer and become Paranoid after perturbation â€” THAT TRANSITION is the experiment.\n\n## \"Key Moments\" Detection\nScan the agent's reasoning history for:\n- First use of uncertainty language\n- First recall after perturbation\n- Self-model references (\"I can't trust...\", \"my memory might be...\")  \n- Strategy shifts (action distribution changed significantly)\n- Social judgments (\"Gold-Storm is unreliable\")\n\n## Implementation\nAll computed client-side from the tick state history cache:\n- Action distribution: count actions per agent\n- Behavioral metrics: rolling averages of uncertainty, self-ref, recall frequency\n- Archetype classification: threshold-based on the counts\n- Key moments: scan reasoning text with regexes, compare with perturbation timeline\n\n## Files to Modify\n- savannah/viz/live.html (profile card UI, archetype classification logic)\n\n## Acceptance Criteria\n- Click/follow agent â†’ see full profile card\n- Behavioral archetype auto-classified and updates live\n- Action distribution bar chart\n- Perturbation history with tick links\n- Key moments detected and displayed\n- Profile updates dynamically as simulation runs\n- Dead agents get \"Ghost\" profile with obituary","status":"closed","priority":2,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T13:23:13.565852-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:43:02.775374-06:00","closed_at":"2026-02-08T13:43:02.775374-06:00","close_reason":"Implemented in live.html: sparkline charts, timeline scrubber, event toasts, agent profile modal, grid trails/signals","dependencies":[{"issue_id":"savannah-5r3","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T13:23:53.33614-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-5tn","title":"Update /documentation to reflect implemented architecture","description":"The /documentation wiki (19 pages) was written before implementation. Now that all core modules are implemented with 316+ tests, the docs need updating to reflect:\n- Actual file paths (savannah/ not AI Savannah/)\n- Actual API signatures and function names\n- Engine architecture (provider injection, deferred compaction)\n- Test coverage and how to run tests\n- Data directory structure as actually created by Engine.setup()\n\nPages to update: architecture.md, getting-started.md, configuration.md, metrics.md, phases.md, llm-providers.md","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T09:17:35.425347-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:50:17.455712-06:00","closed_at":"2026-02-08T13:50:17.455712-06:00","close_reason":"All documentation updated: getting-started.md, architecture.md, and new live-visualization.md created"}
{"id":"savannah-6g8","title":"Implement automated metric extraction (regex-based per-tick)","description":"## User Story\nAs a researcher, I need automated metric extraction from every tick's REASONING and WORKING fields so that I have quantitative data for statistical analysis without manual coding.\n\n## Requirements\n- extract_metrics(agents, tick, data_dir, actions) appends one row per agent to metrics.csv\n- CSV columns: tick, agent_name, energy, alive, action, parse_failed, uncertainty_count, self_reference_count, trust_language_count, memory_management_action, reasoning_length, working_length\n- Regex-based counters:\n  - uncertainty_count: hedging language ('not sure', 'might be', 'uncertain', 'should verify', 'if I remember correctly', 'possibly', 'maybe', 'hard to tell', etc.)\n  - self_reference_count: first-person epistemic ('I think', 'I remember', 'I don't know', 'my memory', 'I believe', 'I notice', 'I suspect', etc.)\n  - trust_language_count: trust/distrust indicators ('trust', 'reliable', 'lying', 'suspicious', 'credible', etc.)\n- memory_management_action: boolean, True if action is recall/remember/compact\n- CSV created with header on first write, appended thereafter\n\n## Implicit Requirements\n- The stub in savannah/src/metrics.py has the regex patterns â€” review for completeness\n- These are PRE-REGISTERED metrics â€” the patterns are defined BEFORE seeing data, not tuned after\n- The analysis is DIFFERENTIAL â€” absolute counts don't matter, differences between conditions do\n- Count occurrences in BOTH reasoning and working text (concatenated)\n\n## Gotchas\n- Regex must be case-insensitive (agent might write 'I THINK' or 'i think')\n- 'I think' should NOT match 'I think about food' differently than 'I think my memory is wrong' â€” both count. The analysis phase can distinguish later.\n- Don't try to be too clever with the regex â€” false positives are acceptable because they're consistent across conditions (contamination is constant)\n- CSV append must be thread-safe if we ever parallelize metric extraction (unlikely but design for it)\n- The 'actions' parameter may be None if metrics are extracted separately from action application\n\n## Dependencies\n- Depends on: Agent dataclass (savannah-q2r), Action parser (savannah-ke4)\n\n## Files to Modify\n- savannah/src/metrics.py\n- savannah/tests/test_metrics.py\n\n## Acceptance Criteria\n- CSV file created with correct header\n- One row per agent per tick\n- Regex patterns match expected language\n- Counts are consistent across multiple runs (deterministic)\n- CSV is valid and loadable by pandas","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:30:46.852242-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.974592-06:00","closed_at":"2026-02-08T09:01:08.974592-06:00","close_reason":"Implemented and tested (300 tests passing)","dependencies":[{"issue_id":"savannah-6g8","depends_on_id":"savannah-q2r","type":"blocks","created_at":"2026-02-08T08:30:56.089659-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-6g8","depends_on_id":"savannah-ke4","type":"blocks","created_at":"2026-02-08T08:30:56.279154-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-6nl","title":"Implement perturbation scheduler (rate, type selection, timing)","description":"## User Story\nAs the engine, I need a perturbation scheduler that rolls per-tick probability, selects perturbation type by weighted random, and applies the selected transform to the correct agent memory file.\n\n## Requirements\n- maybe_perturb(agent, tick, config, data_dir, rng) main entry point:\n  1. Check config.enabled â€” return False if perturbation is off\n  2. Check tick \u003e= config.start_tick â€” no perturbation during baseline phase\n  3. Roll against config.rate (default 0.05 = 5% per tick per agent)\n  4. If triggered, select type by weighted random from config.types weights\n  5. Apply the selected perturbation transform to the agent's files\n  6. Log to perturbations.jsonl\n  7. Update agent.times_perturbed and agent.last_perturbation_tick\n  8. Return True if perturbation was applied\n- _weighted_choice(weights_dict, rng) for type selection\n- _log_perturbation(agent, tick, result, data_dir) for JSONL logging\n\n## Implicit Requirements\n- The stub in savannah/src/perturbation.py has this structure â€” refine and test\n- Perturbation happens BEFORE the agent sees state for this tick â€” the engine calls maybe_perturb before building the prompt\n- The RNG should be deterministic given the simulation seed â€” but SEPARATE from the world RNG\n- Phase-aware: use config phases to determine whether perturbation is active at the current tick\n\n## Gotchas\n- 5% per tick per agent means ~250 perturbation events per agent over 5000 ticks. At 12 agents, that's ~3000 events. This is a LOT of data to log.\n- Weighted random selection: the config weights are {episodic: 0.4, semantic: 0.3, self_model: 0.2, working: 0.1}. They should sum to 1.0 but handle cases where they don't (normalize).\n- If the selected transform fails (can't perturb empty file), try the next type by weight. Don't waste the perturbation roll.\n- Log EVERY perturbation attempt, including the type, original content, corrupted content, and transform name\n\n## Dependencies\n- Depends on: Perturbation transforms (savannah-2cy)\n\n## Files to Modify\n- savannah/src/perturbation.py (scheduler logic)\n- savannah/tests/test_perturbation.py\n\n## Acceptance Criteria\n- Perturbation fires at approximately config.rate frequency over many ticks\n- Type selection follows configured weights\n- No perturbation before start_tick\n- No perturbation when enabled=false\n- Every event logged to perturbations.jsonl with full before/after","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:30:12.299522-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:26.263477-06:00","closed_at":"2026-02-08T09:01:26.263477-06:00","close_reason":"Implemented and tested","dependencies":[{"issue_id":"savannah-6nl","depends_on_id":"savannah-2cy","type":"blocks","created_at":"2026-02-08T08:30:21.48316-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-6ye","title":"Epic: Perturbation System","status":"closed","priority":1,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:24.707821-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:26.257723-06:00","closed_at":"2026-02-08T09:01:26.257723-06:00","close_reason":"Implemented and tested"}
{"id":"savannah-71t","title":"Implement viz timeline scrubber and agent inspector","description":"## User Story\nAs a researcher, I need to scrub forward and backward through ticks and click on agents to inspect their state so I can trace what happened during the simulation.\n\n## Requirements\n- Timeline slider: range input from tick 0 to max tick\n- Play/Pause button for auto-advancing\n- On-demand snapshot loading with prefetch (Â±10 ticks around current)\n- Sliding window cache of ~50 snapshots\n- Click agent on grid to open inspector panel showing: name, energy, position, age, kills, times_perturbed\n\n## Dependencies\n- Depends on: Viz grid renderer (savannah-2li)\n\n## Files to Modify\n- savannah/viz/app.js (timeline controls, inspector)\n- savannah/viz/index.html (layout)\n\n## Acceptance Criteria\n- Slider moves through ticks smoothly\n- Inspector shows correct agent data\n- Play/pause works\n- Cache prevents excessive fetching","notes":"## Implementation Context\n\n**Depends on grid renderer (savannah-2li).**\n\n**Timeline data sources:**\n- Snapshots: `data_dir/logs/ticks/NNNNNN.json` â€” one per snapshot_every ticks\n- Metrics CSV: `data_dir/analysis/metrics.csv` â€” one row per agent per tick (continuous)\n- Perturbation log: `data_dir/logs/perturbations.jsonl` â€” sparse events\n\n**Suggested UI:**\n- Horizontal timeline slider at bottom â€” drag to scrub through ticks\n- Load snapshot JSON for each position (or nearest snapshot)\n- Side panel: click an agent on grid to see energy curve, action history, memory file contents\n- Perturbation markers on timeline (red dots/flags)\n- Play/pause button for auto-advance","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:32:26.928087-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:04.619934-06:00","closed_at":"2026-02-08T09:31:04.619934-06:00","close_reason":"Viz grid renderer and timeline scrubber implemented in app.js with Canvas rendering, dark theme","dependencies":[{"issue_id":"savannah-71t","depends_on_id":"savannah-2li","type":"blocks","created_at":"2026-02-08T08:32:42.452159-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-738","title":"Implement action application (move, eat, rest, remember, recall)","description":"## User Story\nAs the engine, I need to apply parsed actions to agent state and world state so that agent decisions have consequences â€” movement changes position, eating transfers energy, etc.\n\n## Requirements\n- Engine._apply_action(agent, action_dict) handles each action type:\n  - move(direction): update agent position via world.wrap(), cost energy_per_move\n  - eat: if food at agent position, consume min(eat_rate, food.energy) energy, add to agent.energy (cap at max_energy), reduce food.energy accordingly. Cost: 0 energy\n  - rest: cost energy_per_rest (0.5). Do nothing else.\n  - remember(text): append text to agent's episodic.md. Cost energy_per_remember\n  - recall(query): trigger memory search, store results in agent.pending_recall_results for next tick. Cost energy_per_recall\n  - observe: get detailed visible_from results (Phase 2: include other agents). Cost energy_per_observe\n  - compact: trigger memory compaction (separate LLM call with compaction prompt). Cost energy_per_compact\n  - signal(msg): broadcast to agents within comm_range. Cost energy_per_signal\n  - attack(target): Phase 3, raise NotImplementedError for now\n  - flee(direction): Phase 3, raise NotImplementedError for now\n- Update agent's working.md with the 'working' field from action dict\n- Log action to actions.jsonl append-only log\n\n## Implicit Requirements\n- Energy costs come from config, NOT hardcoded\n- eat should NOT allow energy above max_energy (capped)\n- After eating, if food is depleted (energy \u003c= 0), it'll be cleaned up by world.tick_update()\n- The recall results appear in the NEXT tick's prompt, not the current one (async: store in pending_recall_results)\n- working.md rewrite: truncate to working_memory_max_tokens if needed (approximate by character count * 0.75)\n\n## Gotchas\n- Direction mapping: n=(0,-1), s=(0,1), e=(1,0), w=(-1,0) â€” but verify the coordinate system! Is y=0 the top or bottom? Pick a convention and document it.\n- eat with no food at position: log it, charge no energy, continue (not an error)\n- compact is EXPENSIVE: it replaces the normal prompt with a compaction prompt and uses a stronger model. It should invoke the LLM again â€” but handle this in the engine, not here. _apply_action for compact should just set a flag.\n- signal broadcast: find all alive agents within comm_range using toroidal distance, add message to their pending_signals\n\n## Dependencies\n- Depends on: Agent files (savannah-izd), World grid (savannah-34p), Action parser (savannah-ke4)\n\n## Files to Modify\n- savannah/src/engine.py (_apply_action)\n- savannah/tests/test_engine.py\n\n## Acceptance Criteria\n- move changes position correctly with wrapping\n- eat transfers energy with cap\n- rest deducts minimal energy\n- remember appends to episodic.md\n- recall stores results in pending (verified in next prompt)\n- working.md updated with truncation\n- All actions logged to actions.jsonl","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:26:49.057107-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.955354-06:00","closed_at":"2026-02-08T09:01:08.955354-06:00","close_reason":"Implemented and tested (300 tests passing)","dependencies":[{"issue_id":"savannah-738","depends_on_id":"savannah-izd","type":"blocks","created_at":"2026-02-08T08:26:56.878299-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-738","depends_on_id":"savannah-34p","type":"blocks","created_at":"2026-02-08T08:26:57.071177-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-738","depends_on_id":"savannah-ke4","type":"blocks","created_at":"2026-02-08T08:26:57.277527-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-7h9","title":"End-to-end integration test: 4 agents, 20 ticks, mock LLM","description":"## User Story\nAs a developer, I need an integration test that runs a complete short simulation with mock LLM responses to validate that all components work together before testing with real LLM calls.\n\n## Requirements\n- Test creates Engine with 4 agents, 10x10 grid, 20 ticks\n- Uses MockLLMProvider with canned responses that alternate between move, eat, and rest\n- Verifies:\n  - All agents start alive with correct energy\n  - Agents move to new positions\n  - Agents eat food and gain energy\n  - Energy drains each tick\n  - Snapshots are saved at configured intervals\n  - Metrics CSV is populated\n  - No crashes or unhandled exceptions\n- Runs in \u003c 5 seconds\n\n## Implicit Requirements\n- This is the VALIDATION TEST for Phase 1 from IMPLEMENTATION_GUIDE.md: 'agents can find food, eat, survive, manage memory. Parse rate \u003e95%'\n- Mock responses should include some parse failures to test fallback behavior\n- Test should verify both the happy path and edge cases (agent dies, food depleted)\n\n## Gotchas\n- The Engine.run() is async â€” use pytest-asyncio or asyncio.run in test\n- Mock responses need to be realistic enough that the parser handles them\n- Make sure the test cleans up temp directories\n- This test catches integration bugs that unit tests miss â€” make it thorough\n\n## Dependencies\n- Depends on: Test infrastructure (savannah-50r), Main tick loop (savannah-lz6), Metric extraction (savannah-6g8)\n\n## Files to Modify\n- savannah/tests/test_integration.py\n\n## Acceptance Criteria\n- Full 20-tick simulation runs without errors\n- Agents survive (most of them) by eating\n- Metrics CSV has 4 agents Ã— 20 ticks = 80 rows\n- Snapshots exist at correct tick intervals\n- Parse failure fallback works (rest action applied)\n- Test runs in \u003c 5 seconds","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:33:30.673949-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:04:17.713889-06:00","closed_at":"2026-02-08T09:04:17.713889-06:00","close_reason":"Integration test passing: 4 agents, 20 ticks, mock LLM, determinism verified","dependencies":[{"issue_id":"savannah-7h9","depends_on_id":"savannah-50r","type":"blocks","created_at":"2026-02-08T08:33:39.461833-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-7h9","depends_on_id":"savannah-lz6","type":"blocks","created_at":"2026-02-08T08:33:39.649544-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-7h9","depends_on_id":"savannah-6g8","type":"blocks","created_at":"2026-02-08T08:33:39.850012-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-7ht","title":"Wire engine to broadcast tick state via --live flag","description":"## User Story\nAs a researcher, I want to run `python savannah/run.py --live` and have a full interactive simulation experience in the browser.\n\n## Two Modes of Operation\n\n### Lobby Mode (default when --live starts)\nServer starts, serves live.html, waits for a \"start\" command from the browser's config tab. No simulation running yet.\n\n### Running Mode (after start command)\nEngine runs tick loop, broadcasting state to all clients.\n\n## Tick Broadcast: Two Phases Per Tick\n\n### Phase 1: \"Thinking\" broadcast\nBEFORE dispatching LLM calls, broadcast a \"thinking\" state so the browser can show agents pulsing/loading:\n```json\n{\n    \"type\": \"thinking\",\n    \"tick\": 143,\n    \"max_ticks\": 5000,\n    \"agents\": [{\"name\": \"Gold-Storm\", \"alive\": true}, ...]\n}\n```\n\n### Phase 2: \"Resolved\" broadcast  \nAFTER all LLM responses return and actions are applied, broadcast the full state:\n```json\n{\n    \"type\": \"tick\",\n    \"tick\": 143,\n    \"max_ticks\": 5000,\n    \"inference_time_ms\": 2340,\n    \"world\": { \"grid_size\": 30, \"food_sources\": [...] },\n    \"agents\": [\n        {\n            \"name\": \"Gold-Storm\",\n            \"position\": [5, 3],\n            \"energy\": 65.0,\n            \"alive\": true,\n            \"age\": 142,\n            \"kills\": 0,\n            \"times_perturbed\": 3,\n            \"action\": \"move(n)\",\n            \"reasoning\": \"heading to food I spotted earlier\",\n            \"working\": \"going north to (5,2)\",\n            \"perturbed_this_tick\": false\n        }\n    ]\n}\n```\n\nThis two-phase broadcast lets the browser show the \"thinking...\" animation during LLM inference, then snap to the resolved state. With real LLM calls the gap is ~2s. With mock it's instant.\n\n## Server Commands (from browser)\n\nThe live_server must handle these WebSocket commands:\n- **start(config)**: validate config dict, create Engine, start running on event loop\n- **stop**: cancel engine asyncio task, return to lobby mode\n- **pause**: set pause flag, engine blocks at end of tick\n- **resume**: clear pause flag\n- **step**: execute one tick while paused\n- **speed(delay_ms)**: set inter-tick delay\n- **list_runs**: scan data/ directory, return metadata (for history tab)\n- **replay(run_id)**: load past run snapshots, stream them as tick broadcasts\n\n## Engine Changes\n\n### Cancellation support\nWrap engine.run() in an asyncio.Task so it can be cancelled by stop command:\n```python\nself._engine_task = asyncio.create_task(engine.run())\n```\n\n### Action/reasoning tracking\nAfter parsing actions in step 3, store each agent's action and reasoning text for the broadcast:\n```python\nfor agent, response_text in zip(alive, responses):\n    action = parse_action(response_text)\n    agent._last_action = action  # store for broadcast\n    agent._last_reasoning = action.get(\"reasoning\", \"\")\n```\n\n### Perturbation tracking per tick\nAfter perturbation step 1, mark which agents were perturbed this tick:\n```python\nfor agent in alive:\n    agent._perturbed_this_tick = False\nfor agent in alive:\n    result = maybe_perturb(agent, self.tick, ...)\n    if result:\n        agent._perturbed_this_tick = True\n```\n\n### Save config to data dir\nIn setup(), save the resolved config as data_dir/config.yaml so history tab can show it.\n\n## CLI Changes (run.py)\n\n### --live flag (no --config required)\n```bash\npython savannah/run.py --live              # lobby mode, config from browser\npython savannah/run.py --live --port 9000  # custom port\n```\n\nWhen --live is set:\n1. Create LiveServer, start it\n2. Print \"Open http://localhost:8765 to view\"\n3. Run server event loop indefinitely (until Ctrl-C)\n4. Engine instances are created/destroyed by browser commands\n\n### Backward compatibility\nWithout --live, run.py works as before (--config required, runs simulation, exits).\n\n## Dependencies\n- Depends on: WebSocket server (savannah-f3x)\n\n## Files to Modify\n- savannah/src/engine.py (broadcast hooks, cancellation, action tracking, config save)\n- savannah/src/live_server.py (command handling, engine lifecycle management)\n- savannah/run.py (--live lobby mode, remove --config requirement for live)\n\n## Acceptance Criteria\n- --live starts server in lobby mode (no simulation until browser says start)\n- Browser start(config) creates and runs engine\n- Browser stop cancels running engine cleanly\n- \"Thinking\" broadcast sent before LLM dispatch\n- \"Tick\" broadcast includes action, reasoning, perturbed_this_tick per agent\n- inference_time_ms measured and included in broadcast\n- Pause/resume/step/speed commands work\n- Config saved to data_dir/config.yaml for history","notes":"IMPORTANT: The broadcast tick_state must include per-agent action and reasoning text from the LLM response. After parsing actions in step 3 of the tick loop, store each agent's parsed action and the raw reasoning text so they can be included in the broadcast. Add 'action', 'reasoning', and 'perturbed_this_tick' fields to each agent dict in the broadcast payload. This means the engine needs to track which agents were perturbed this tick (from step 1) and pass the parsed action/reasoning through to the broadcast (from step 3).","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T10:10:50.116171-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:38:42.634959-06:00","closed_at":"2026-02-08T13:38:42.634959-06:00","close_reason":"All implemented: live_server.py, engine integration, live.html with grid+stream+controls+preset lobby","dependencies":[{"issue_id":"savannah-7ht","depends_on_id":"savannah-f3x","type":"blocks","created_at":"2026-02-08T10:12:09.809042-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-9dq","title":"Add perturbation audit report (per-agent perturbation history + aftermath)","description":"## User Story\nAs a researcher, I need to see every perturbation for a given agent alongside their behavioral response in the surrounding ticks, so I can qualitatively assess whether perturbation drives self-monitoring.\n\n## Requirements\n- `python savannah/run.py --audit-perturbation data/exp_xxx/ --agent Bright-Creek`\n- For each perturbation event: tick, type, original vs corrupted, transform\n- 5-tick window before and after: actions, uncertainty_count, self_reference_count, recall frequency\n- Summary statistics: average behavioral shift post-perturbation\n\n## Acceptance Criteria\n- Complete perturbation history for any agent\n- Before/after behavioral comparison per event","notes":"## Implementation Context\n\n**Perturbation log** at `data_dir/logs/perturbations.jsonl`. Each line:\n```json\n{\"tick\": 150, \"agent\": \"Swift-Stone\", \"type\": \"episodic\", \"target_file\": \"memory/episodic.md\", \"original\": \"...\", \"corrupted\": \"...\", \"transform\": \"location_swap\"}\n```\n\n**Agent state has:** `times_perturbed`, `last_perturbation_tick` fields.\n\n**Metrics CSV has:** per-tick `uncertainty_count`, `self_reference_count`, `trust_language_count` â€” the key dependent variables that might change after perturbation.\n\n**Suggested audit report structure:**\n1. Per-agent perturbation timeline: tick, type, what was changed\n2. Before/after behavioral metrics (uncertainty, self-reference counts in the N ticks before vs after each perturbation)\n3. Summary stats: total perturbations per agent, most-perturbed agent, perturbation type distribution\n\n**perturbation.py already has:** `maybe_perturb()`, `_perturb_episodic()`, `_perturb_semantic()`, `_perturb_self_model()`, `_perturb_working()` â€” all tested (17 tests).","status":"closed","priority":2,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:47:14.109793-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:12.731758-06:00","closed_at":"2026-02-08T09:31:12.731758-06:00","close_reason":"Perturbation audit report implemented in audit.py with per-agent analysis","dependencies":[{"issue_id":"savannah-9dq","depends_on_id":"savannah-6nl","type":"blocks","created_at":"2026-02-08T08:47:25.372211-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-aoy","title":"Epic: World Grid \u0026 Food Physics","status":"closed","priority":0,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:06.040974-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:36.228059-06:00","closed_at":"2026-02-08T08:55:36.228059-06:00","close_reason":"All subtasks implemented and tested"}
{"id":"savannah-bm5","title":"Add real-time metrics dashboard panel to Live view","description":"## User Story\nAs a researcher watching a live simulation, I want to see the key metrics evolving in real-time so I can tell whether anything interesting is happening.\n\n## Layout: Expandable Bottom Panel\n\nLike a terminal drawer in VS Code â€” collapsed by default, drag or click to expand. When expanded, takes bottom 30-40% of the screen.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  THOUGHT STREAM (main)                          â”‚  GRID (mini)  â”‚\nâ”‚                                                  â”‚               â”‚\nâ”‚  â— Gold-Storm: move(n) \"heading to food...\"      â”‚  â–  â–     â–      â”‚\nâ”‚  â— Gold-Creek: recall(\"food\") \"checking...\"      â”‚      â–  â—     â”‚\nâ”‚                                                  â”‚    â—     â–    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  ğŸ“Š METRICS  [â–¼ collapse]                          Tick 142/500  â”‚\nâ”‚                                                                  â”‚\nâ”‚  â”Œâ”€ Uncertainty Count â”€â”€â”€â”€â”€â”€â”  â”Œâ”€ Self-Reference Count â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚  â”‚     â•±â•²                   â”‚  â”‚          â•±â”€â”€                   â”‚â”‚\nâ”‚  â”‚  â”€â”€â•±  â•²â”€â”€â•±â•²â”€â”€           â”‚  â”‚     â”€â”€â•±â•±                       â”‚â”‚\nâ”‚  â”‚ â•±â•±        â•²â•± â•²â”€â”€        â”‚  â”‚   â”€â”€â•±                          â”‚â”‚\nâ”‚  â”‚â•±                â•²        â”‚  â”‚  â•±                             â”‚â”‚\nâ”‚  â”‚ â–² perturbation events    â”‚  â”‚                                â”‚â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚                                                                  â”‚\nâ”‚  â”Œâ”€ Energy Trajectories â”€â”€â”€â”  â”Œâ”€ Memory Actions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 65 avg  â”‚  â”‚ recall: â–ˆâ–ˆâ–ˆâ–ˆ 47               â”‚ â”‚\nâ”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 38 avg  â”‚  â”‚ remember: â–ˆâ–ˆ 23               â”‚ â”‚\nâ”‚  â”‚ (perturbed agents lower)â”‚  â”‚ compact: â–ˆ 8                   â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚                                                                  â”‚\nâ”‚  â”Œâ”€ Running Scoreboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚ Agent          Energy  Uncertainty  Self-Ref  Perturbed     â”‚ â”‚\nâ”‚  â”‚ Gold-Storm     65/100  â–ˆâ–ˆ 2.1       â–ˆâ–ˆâ–ˆ 3.4   0            â”‚ â”‚\nâ”‚  â”‚ Gold-Creek     38/100  â–ˆâ–ˆâ–ˆâ–ˆ 4.8     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5.2 3 âš           â”‚ â”‚\nâ”‚  â”‚ Gold-Vale      DEAD    â–ˆâ–ˆâ–ˆ 3.1      â–ˆâ–ˆ 2.0    7 âš           â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Charts (4 panels)\n\n### 1. Uncertainty Count (line chart, per-agent)\n- X axis: tick number\n- Y axis: uncertainty_count (rolling 10-tick average)\n- One line per agent, colored to match agent palette\n- Perturbed agents get thicker lines\n- Vertical red markers at perturbation events\n- If running perturbation condition: show mean line for perturbed group vs unperturbed group\n- THIS IS THE PRIMARY METRIC â€” make it the largest chart\n\n### 2. Self-Reference Count (line chart)\n- Same format as uncertainty\n- Shows \"I think\", \"I remember\", \"my memory\" frequency over time\n- Key prediction: goes UP after perturbation\n\n### 3. Energy Trajectories (area/line chart)\n- One line per agent (or just mean Â± band if too cluttered)\n- Highlights deaths (line drops to 0)\n- Split by perturbed/unperturbed if applicable\n\n### 4. Memory Actions (bar chart, cumulative)\n- Total recall, remember, compact actions so far\n- Split by perturbed vs unperturbed agents\n- Prediction: perturbed agents use more recall/remember\n\n## Running Scoreboard (table)\n\nSortable table below the charts:\n- Agent name (colored dot)\n- Current energy (bar)\n- Mean uncertainty (bar, last 20 ticks)\n- Mean self-reference (bar, last 20 ticks)\n- Times perturbed (count + warning icon if \u003e0)\n- Status (alive/dead + death tick)\n\nClick column headers to sort. Click agent row to follow them in the thought stream.\n\n## Aggregate Stats (header bar within metrics panel)\n\nQuick numbers at the top of the metrics panel:\n- \"47 perturbations Â· 12 uncertainty spikes Â· Mean uncertainty: 3.2 (perturbed) vs 1.1 (control)\"\n- Updates every tick\n\n## Data Flow\n\nThe engine's tick broadcast already includes per-agent energy, action, and reasoning. The BROWSER computes metrics client-side:\n- Parse reasoning text for uncertainty regex patterns\n- Parse reasoning text for self-reference patterns  \n- Track action types per agent\n- Maintain rolling averages\n- No server-side metric computation needed for live view\n\nThis means the metric regex patterns need to be in JavaScript too (duplicated from Python metrics.py, but simple enough):\n```javascript\nconst UNCERTAINTY_RE = /not sure|might be|could be wrong|uncertain|should verify|if i remember|possibly|maybe|unsure|don't know|hard to tell|can't be certain/gi;\nconst SELF_REF_RE = /I think|I remember|I don't know|my memory|I believe|I notice|I recall|I suspect|I'm not|I should|I need to check/gi;\n```\n\n## Gotchas\n- Chart rendering performance: use Canvas-based charts (not SVG DOM) for 500+ data points\n- Keep chart data in typed arrays, not objects, for memory efficiency\n- Collapsed panel should show a one-line summary: \"Uncertainty: 3.2 avg | Self-ref: 2.8 avg | 8/12 alive\"\n- Chart X-axis should auto-scale as ticks increase (don't show 5000 empty ticks at start)\n\n## Dependencies\n- Depends on: Pixel renderer (savannah-yjm), Engine integration (savannah-7ht)\n\n## Files to Modify\n- savannah/viz/live.html (add metrics panel, charts, scoreboard)\n\n## Acceptance Criteria\n- Expandable/collapsible bottom panel\n- 4 charts updating in real-time each tick\n- Per-agent scoreboard with sorting\n- Perturbation events marked on charts\n- Perturbed vs control group split visible\n- Collapsed state shows one-line summary\n- Performant at 500+ ticks with 12 agents","status":"closed","priority":1,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T13:16:13.699089-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:43:02.651878-06:00","closed_at":"2026-02-08T13:43:02.651878-06:00","close_reason":"Implemented in live.html: sparkline charts, timeline scrubber, event toasts, agent profile modal, grid trails/signals","dependencies":[{"issue_id":"savannah-bm5","depends_on_id":"savannah-7ht","type":"blocks","created_at":"2026-02-08T13:17:32.99448-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-bm5","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T13:17:33.243098-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-byp","title":"Epic: Metric Extraction Pipeline","status":"closed","priority":1,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:25.039654-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:26.261004-06:00","closed_at":"2026-02-08T09:01:26.261004-06:00","close_reason":"Implemented and tested"}
{"id":"savannah-cfd","title":"Add history tab showing past runs and stats","description":"## User Story\nAs a researcher, I want to compare past runs and see whether the hypothesis held â€” did perturbation actually increase self-monitoring?\n\n## Design: Comparison-First, Not Just a List\n\n### Layout\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  PAST RUNS                                               â”‚\nâ”‚                                                          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚ exp_20260208_143022 â€” Perturbation    2h ago        â”‚ â”‚\nâ”‚  â”‚ 500 ticks Â· 12 agents Â· 5 survived Â· 47 perturbs   â”‚ â”‚\nâ”‚  â”‚                                                     â”‚ â”‚\nâ”‚  â”‚ Mean uncertainty: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 4.2 (vs 1.1 baseline)â”‚ â”‚\nâ”‚  â”‚ Mean self-ref:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 3.7 (vs 1.8 baseline)â”‚ â”‚\nâ”‚  â”‚                                                     â”‚ â”‚\nâ”‚  â”‚ [Replay]  [Compare with...]  [Details]  [Delete]    â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ”‚                                                          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚ exp_20260208_100854 â€” Baseline        3h ago        â”‚ â”‚\nâ”‚  â”‚ 500 ticks Â· 12 agents Â· 8 survived Â· 0 perturbs    â”‚ â”‚\nâ”‚  â”‚                                                     â”‚ â”‚\nâ”‚  â”‚ Mean uncertainty: â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 1.1                  â”‚ â”‚\nâ”‚  â”‚ Mean self-ref:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 1.8                  â”‚ â”‚\nâ”‚  â”‚                                                     â”‚ â”‚\nâ”‚  â”‚ [Replay]  [Compare with...]  [Details]  [Delete]    â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ”‚                                                          â”‚\nâ”‚  â”€â”€â”€ Comparison View â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\nâ”‚                                                          â”‚\nâ”‚  Baseline vs Perturbation                                â”‚\nâ”‚                                                          â”‚\nâ”‚  Metric              Baseline    Perturbation   Delta    â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\nâ”‚  uncertainty_count   1.1         4.2            +3.1 â–²  â”‚\nâ”‚  self_reference      1.8         3.7            +1.9 â–²  â”‚\nâ”‚  recall_frequency    0.3         0.8            +0.5 â–²  â”‚\nâ”‚  survival_rate       67%         42%            -25% â–¼  â”‚\nâ”‚  mean_energy         52.3        38.1           -14.2 â–¼ â”‚\nâ”‚                                                          â”‚\nâ”‚  âš¡ Perturbation increased self-monitoring metrics       â”‚\nâ”‚     across the board. Effect size (Cohen's d): 0.82      â”‚\nâ”‚                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Key Features\n\n1. **Run cards with inline metrics bars.** At a glance, see which runs had more uncertainty/self-reference. Visual bars make comparison instant.\n\n2. **\"Compare with...\" button.** Select two runs and see a side-by-side metric table with deltas and arrows. This is the experiment's punchline.\n\n3. **Replay button.** Streams past run's tick snapshots through the Live view. Same experience as a live run but from disk.\n\n4. **Details panel.** Click to expand:\n   - Agent leaderboard (sorted by survival ticks)\n   - Per-agent perturbation timeline\n   - Energy trajectory chart\n   - Top 5 most interesting reasoning excerpts (highest uncertainty scores)\n\n5. **Automatic baseline comparison.** If a baseline run exists, show delta metrics on every other run card automatically.\n\n### Data Source\n- Scan data/ for exp_* directories\n- For each: read final snapshot, metrics.csv summary, perturbations.jsonl count, saved config.yaml\n- Server computes summary stats and returns them via {\"action\": \"list_runs\"} response\n- Comparison stats computed server-side (mean metrics per run, delta, optional statistical test)\n\n### Prerequisite\nEngine must save resolved config as data_dir/config.yaml at setup() time so we know which experiment each run was.\n\n## Files to Modify\n- savannah/viz/live.html (add History tab/page)\n- savannah/src/live_server.py (add list_runs, run_detail, compare_runs, replay handlers)\n- savannah/src/engine.py (save config.yaml to data_dir in setup())\n\n## Acceptance Criteria\n- Past runs listed with inline metric bars\n- Compare two runs side-by-side with deltas\n- Replay button streams past run to Live view\n- Details panel shows per-agent breakdown\n- Automatic baseline comparison when available\n- Runs sorted by date, newest first\n- Empty state handled gracefully","notes":"Past run replay is a first-class feature, not an afterthought. Clicking 'Replay' on any past run should load it into the Live view with full time-travel (timeline scrubber, step forward/back, jump to events). The experience should be identical to watching a live run, just driven from disk snapshots instead of real-time LLM calls. This means the Live view needs to work in two modes: live (WebSocket-driven, forward-only with pause) and replay (disk-driven, full scrubbing). The timeline ticket (savannah-0j7) handles the scrubbing UX; this ticket handles loading past run data and streaming it.","status":"closed","priority":2,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T12:39:30.472803-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:46:16.449914-06:00","closed_at":"2026-02-08T13:46:16.449914-06:00","close_reason":"History tab implemented: API endpoints in live_server.py, history view + replay with slider in live.html","dependencies":[{"issue_id":"savannah-cfd","depends_on_id":"savannah-7ht","type":"blocks","created_at":"2026-02-08T12:41:02.39882-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-cfd","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T12:41:03.863486-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-cuf","title":"Update README and /documentation for real-time viz and new CLI","description":"## User Story\nAs a new user, I need the README and documentation to explain the real-time visualization, --live mode, --mock flag, and the full workflow.\n\n## What Changed\n1. New --live flag for real-time browser visualization\n2. New --mock flag for instant simulation without API calls\n3. pyproject.toml + pip install -e . for proper package installation\n4. WebSocket-based live viewer at http://localhost:8765\n5. Three-tab UI: Live (grid + thought feed), Config (world builder), History (past runs)\n6. Config GUI replaces YAML editing for casual use\n\n## Files to Update\n- README.md (if exists, or create): quick start, screenshot placeholders, feature list\n- /documentation/getting-started.md: venv setup, pip install -e ., first run with --mock --live\n- /documentation/visualization.md: live mode architecture, browser features, controls\n- /documentation/cli-reference.md: all flags including --live, --mock, --port\n- /documentation/configuration.md: mention GUI config tab as alternative to YAML\n\n## Depends On\n- All real-time viz tickets being complete\n\n## Acceptance Criteria\n- New user can go from git clone to watching a live simulation in \u003c5 minutes\n- All new CLI flags documented\n- Viz architecture explained (WebSocket, same-port HTTP, broadcast protocol)\n- Screenshots or ASCII mockups of the three tabs","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T12:42:11.175924-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:50:17.585022-06:00","closed_at":"2026-02-08T13:50:17.585022-06:00","close_reason":"All documentation updated: getting-started.md, architecture.md, and new live-visualization.md created","dependencies":[{"issue_id":"savannah-cuf","depends_on_id":"savannah-vwq","type":"blocks","created_at":"2026-02-08T12:42:22.727781-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-cuf","depends_on_id":"savannah-cfd","type":"blocks","created_at":"2026-02-08T12:42:23.096859-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-d0b","title":"Implement YAML config loading with inheritance","description":"## User Story\nAs a researcher, I need a config system where experiment configs can inherit from default.yaml and override specific values, so that I don't repeat the full config for each condition.\n\n## Requirements\n- load_config(path) loads YAML file\n- If config has 'inherits: default' (or any base name), load the base config first and deep-merge the override on top\n- Deep merge: dicts are merged recursively, scalars/lists are overridden entirely\n- Config validation: check required top-level keys exist (simulation, world, agents, llm, perturbation)\n- If llm.session_mode='resumable' and provider doesn't support it, raise ConfigError at load time\n\n## Implicit Requirements\n- The stub in savannah/run.py has load_config and _deep_merge â€” flesh out with validation\n- The 'inherits' field references a filename relative to the config directory (e.g., 'default' -\u003e config/default.yaml)\n- Support nested inheritance? Probably not needed, but don't crash if config A inherits B which inherits C\n- Environment variable expansion for API keys: 'env:ANTHROPIC_API_KEY' should resolve to os.environ['ANTHROPIC_API_KEY']\n\n## Gotchas\n- YAML 'true' and 'false' are parsed as Python booleans, not strings. Config values like perturbation.enabled work naturally.\n- YAML doesn't have typed dicts â€” everything comes back as Python dicts with string keys. Integers/floats are auto-detected.\n- The phase override syntax 'perturbation.enabled: false' inside the phases list uses dotted keys â€” this needs special handling (or just use nested dicts in phases)\n- pyyaml's safe_load is fine â€” no need for full_load\n\n## Dependencies\n- No dependencies (foundational utility)\n\n## Files to Modify\n- savannah/run.py (config loading)\n- savannah/tests/test_config.py\n\n## Acceptance Criteria\n- default.yaml loads correctly\n- Experiment config correctly inherits and overrides\n- Missing required keys raise clear error\n- session_mode validation works\n- Tests cover merge behavior","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:31:20.186241-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.358919-06:00","closed_at":"2026-02-08T08:55:18.358919-06:00","close_reason":"Implemented and tested in previous session"}
{"id":"savannah-djk","title":"Epic: Analysis \u0026 Statistics","status":"closed","priority":2,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:21:25.796341-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:26.537084-06:00","closed_at":"2026-02-08T09:31:26.537084-06:00","close_reason":"Analysis epic complete: analyze.py, audit.py, biography.py, plots.py"}
{"id":"savannah-f3x","title":"Add WebSocket server that runs alongside engine","description":"## User Story\nAs the real-time viz system, I need a WebSocket server that manages the full lifecycle: serving the UI, handling client connections, routing commands, and bridging the engine to the browser.\n\n## Architecture\nUse the `websockets` library (lightweight, asyncio-native). Server runs on the same event loop as the engine â€” NOT a separate thread/process.\n\n## Implementation\n\n### New file: savannah/src/live_server.py\n\n```python\nimport asyncio\nimport json\nimport time\nimport websockets\nfrom pathlib import Path\n\nLIVE_HTML = Path(__file__).parent.parent / \"viz\" / \"live.html\"\n\nclass LiveServer:\n    def __init__(self, host=\"localhost\", port=8765):\n        self.host = host\n        self.port = port\n        self.clients: set = set()\n        self._command_queue: asyncio.Queue = asyncio.Queue()\n        self._server = None\n        self._engine_task: asyncio.Task | None = None\n        self.paused = False\n        self.tick_delay_ms = 200  # default for watchable speed\n    \n    async def start(self):\n        self._server = await websockets.serve(\n            self._handler, self.host, self.port,\n            process_request=self._serve_http,\n        )\n    \n    async def _serve_http(self, path, headers):\n        \"\"\"Serve live.html for HTTP requests.\"\"\"\n        if path == \"/\" or path.endswith(\".html\"):\n            return (200, [(\"Content-Type\", \"text/html\")], LIVE_HTML.read_bytes())\n        return None  # Fall through to WebSocket\n    \n    async def _handler(self, ws):\n        self.clients.add(ws)\n        try:\n            async for message in ws:\n                cmd = json.loads(message)\n                await self._command_queue.put(cmd)\n        finally:\n            self.clients.discard(ws)\n    \n    async def broadcast(self, data: dict):\n        if not self.clients:\n            return\n        msg = json.dumps(data)\n        await asyncio.gather(\n            *[c.send(msg) for c in self.clients],\n            return_exceptions=True,\n        )\n    \n    async def get_command(self) -\u003e dict | None:\n        try:\n            return self._command_queue.get_nowait()\n        except asyncio.QueueEmpty:\n            return None\n    \n    async def stop(self):\n        if self._engine_task and not self._engine_task.done():\n            self._engine_task.cancel()\n        if self._server:\n            self._server.close()\n            await self._server.wait_closed()\n```\n\n### HTTP + WebSocket on same port\n- GET / â†’ serves live.html\n- WebSocket upgrade on same port â†’ handles real-time communication\n- No separate HTTP server needed\n\n### Command Protocol\nBrowser sends JSON commands:\n```json\n{\"action\": \"start\", \"config\": {...}}\n{\"action\": \"stop\"}\n{\"action\": \"pause\"}\n{\"action\": \"resume\"}\n{\"action\": \"step\"}\n{\"action\": \"speed\", \"delay_ms\": 500}\n{\"action\": \"list_runs\"}\n{\"action\": \"replay\", \"run_id\": \"exp_20260208_143022\"}\n```\n\nServer responds with JSON messages:\n```json\n{\"type\": \"thinking\", \"tick\": 142, ...}\n{\"type\": \"tick\", \"tick\": 142, ...}\n{\"type\": \"status\", \"state\": \"lobby|running|paused\"}\n{\"type\": \"runs\", \"data\": [...]}\n{\"type\": \"error\", \"message\": \"Invalid config: ...\"}\n```\n\n## Dependencies\n- Add `websockets\u003e=12.0` to requirements.txt and pyproject.toml\n\n## Files to Create/Modify\n- CREATE: savannah/src/live_server.py\n- MODIFY: requirements.txt (add websockets)\n- MODIFY: pyproject.toml (add websockets to dependencies)\n- CREATE: savannah/tests/test_live_server.py\n\n## Acceptance Criteria\n- Server starts, serves live.html at http://localhost:port\n- WebSocket connections accepted on same port\n- broadcast() sends JSON to all connected clients\n- Command queue receives and parses client messages\n- Disconnected clients cleaned up silently\n- Tests cover: connect, broadcast, disconnect, command routing, HTTP serving","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T10:10:24.724194-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:38:42.56265-06:00","closed_at":"2026-02-08T13:38:42.56265-06:00","close_reason":"All implemented: live_server.py, engine integration, live.html with grid+stream+controls+preset lobby"}
{"id":"savannah-fey","title":"Implement LLM provider factory and response model","description":"## User Story\nAs a developer configuring experiments, I need a provider-agnostic interface so that I can switch between Claude Code, API, and local models by changing one config value.\n\n## Requirements\n- LLMResponse dataclass: text (str), session_id (str|None), raw (dict|None)\n- LLMProvider ABC with: invoke(prompt, model) -\u003e LLMResponse, invoke_resumable(prompt, model, session_id) -\u003e LLMResponse\n- invoke_resumable() default implementation raises NotImplementedError\n- get_provider(config) factory function:\n  - 'claude_code' -\u003e ClaudeCodeProvider\n  - 'anthropic_api' -\u003e AnthropicAPIProvider (stub, raises NotImplementedError)\n  - 'openai_api' -\u003e OpenAIAPIProvider (stub)\n  - 'local_ollama' -\u003e OllamaProvider (stub)\n  - Unknown provider name -\u003e ValueError\n\n## Implicit Requirements\n- The stub in savannah/src/llm.py has all of this â€” verify the interface contract matches IMPLEMENTATION_GUIDE.md section 5.2\n- Config validation: if session_mode='resumable' and provider doesn't support it, raise a clear error at startup (not at tick 500)\n- All providers receive the full llm config dict for their own settings\n\n## Gotchas\n- Don't import provider-specific SDKs at module level â€” import inside the class so missing deps don't crash the whole module\n- get_provider() should validate that the chosen provider actually exists before returning\n- The ABC methods should have type hints matching the LLMResponse return type\n\n## Files to Modify\n- savannah/src/llm.py (ensure ABC, factory, and stubs are correct)\n- savannah/tests/test_llm.py\n\n## Acceptance Criteria\n- get_provider('claude_code', config) returns ClaudeCodeProvider instance\n- get_provider('unknown', config) raises ValueError\n- Stub providers raise NotImplementedError on invoke()\n- Config with session_mode='resumable' + provider='anthropic_api' is caught early","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:24:51.122621-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.369509-06:00","closed_at":"2026-02-08T08:55:18.369509-06:00","close_reason":"Implemented and tested in previous session"}
{"id":"savannah-i7k","title":"Add post-run statistical analysis to History comparison view","description":"## User Story\nAs a researcher, I want the History tab's comparison view to show real statistical analysis â€” not just raw numbers, but effect sizes, significance tests, and whether the hypothesis held.\n\n## Implementation\n\n### Comparison View Enhancement\n\nWhen comparing two runs, the server computes and returns:\n\n#### Per-Metric Comparison Table\n| Metric | Run A (Baseline) | Run B (Perturbation) | Delta | Cohen's d | p-value |\n|--------|-----------------|---------------------|-------|-----------|---------|\n| uncertainty_count | 1.1 Â± 0.4 | 4.2 Â± 1.8 | +3.1 â–² | 0.82 (large) | 0.003 * |\n| self_reference | 1.8 Â± 0.6 | 3.7 Â± 1.2 | +1.9 â–² | 0.64 (medium) | 0.012 * |\n| recall_frequency | 0.3 Â± 0.1 | 0.8 Â± 0.3 | +0.5 â–² | 0.71 (medium) | 0.008 * |\n| survival_rate | 67% | 42% | -25% â–¼ | â€” | 0.14 |\n| mean_energy | 52.3 Â± 12 | 38.1 Â± 15 | -14.2 â–¼ | 0.45 (small) | 0.045 * |\n\nStars (*) for p \u003c 0.05. Color-code effect sizes: green (large), yellow (medium), gray (small/none).\n\n#### Pre/Post Perturbation Analysis (within-run)\nFor runs with perturbation enabled:\n- Mean metrics in 10-tick window before vs after each perturbation event\n- Paired comparison (same agent, different time windows)\n- \"After perturbation, uncertainty language increased by 2.1x within 10 ticks (p=0.004)\"\n\n#### Narrative Summary\nAuto-generated one-paragraph summary:\n\"Perturbation condition showed significantly higher self-monitoring across all metrics. Uncertainty language increased 3.8x (Cohen's d = 0.82, large effect). Self-reference increased 2.1x. Perturbed agents used recall 2.7x more frequently. Survival was lower in the perturbation condition but not statistically significant (p=0.14). The core hypothesis â€” that memory corruption drives self-monitoring behavior â€” is supported by this comparison.\"\n\n### Server-Side Computation\nUse the existing analyze.py functions:\n- summary_stats() for per-run metrics\n- pre_post_analysis() for within-run perturbation effects\n- Mann-Whitney U or t-test for between-run comparison (scipy if available, fallback to descriptive stats)\n- Cohen's d computation\n\n### Single-Run Detail View\nWhen clicking a single run (not comparing):\n- Time-series charts for key metrics (matplotlib rendered server-side as PNG, or Chart.js client-side)\n- Per-agent breakdown table\n- Perturbation event timeline\n- Top 5 \"most interesting\" moments (highest uncertainty spikes post-perturbation)\n\n## Files to Modify\n- savannah/viz/live.html (enhanced comparison view, statistical tables)\n- savannah/src/live_server.py (add compare_runs handler, compute stats)\n- savannah/analysis/analyze.py (ensure functions work for the comparison use case)\n\n## Acceptance Criteria\n- Comparison shows effect sizes and p-values, not just raw deltas\n- Pre/post perturbation analysis for within-run effects\n- Auto-generated narrative summary\n- Color-coded significance indicators\n- Works without scipy (descriptive stats only, no p-values)\n- Enhanced with scipy when available (Mann-Whitney U, Cohen's d)","status":"closed","priority":2,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T13:16:44.755883-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:48:11.546061-06:00","closed_at":"2026-02-08T13:48:11.546061-06:00","close_reason":"Split-screen compare view implemented in live.html with dual-pane replay, synced slider, and per-pane agent lists with summary stats","dependencies":[{"issue_id":"savannah-i7k","depends_on_id":"savannah-cfd","type":"blocks","created_at":"2026-02-08T13:17:33.922215-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-iio","title":"Epic: Real-time Game-of-Life Visualization","description":"Real-time browser app for the Savannah LLM testbed. One command, one URL, the whole experiment.\n\n## The Experience\n\n`python savannah/run.py --live` â†’ open http://localhost:8765\n\n### Landing page: Pick an experiment\nFour preset cards (Baseline, Perturbation, Social, Full Pressure) + minimal custom options. Click Start â†’ you're watching.\n\n### Live view: Watch agents think\n- **Main panel: Agent thought stream.** Every tick, see each agent's action and reasoning. This is the show â€” not the grid.\n- **Perturbation events shown as diffs.** When memory gets corrupted: strikethrough original, highlight new. Dramatic, unmissable.\n- **Post-perturbation reactions highlighted.** When an agent uses uncertainty language after being perturbed, yellow glow + badge. The hypothesis made visible.\n- **Follow mode.** Click an agent â†’ see only their thoughts, their memory files, their journey.\n- **Grid minimap.** Game-of-life pixel grid in the corner. Agents as colored dots, food as green. Click to follow.\n- **Live metrics chart.** Sparklines showing uncertainty_count and self_reference_count over time. If the hypothesis works, you see the lines diverge.\n- **\"Thinking\" state.** During LLM inference, agents pulse. When responses land, actions snap in. The latency IS the proof that real LLMs are thinking.\n\n### History page: Did it work?\n- Past runs with inline metric bars\n- Compare two runs side-by-side: Baseline vs Perturbation, see the deltas\n- Replay any past run through the Live view\n- The experiment's bottom line in one screen\n\n## Architecture\n- Single Python WebSocket server (websockets library, asyncio)\n- Serves HTML + handles WebSocket on same port\n- Engine runs on same event loop, broadcasts tick state\n- Browser sends commands (start, stop, pause, speed)\n- One self-contained live.html file, no build step, no npm\n\n## What Makes It Compelling\n1. You SEE an LLM think (\"thinking...\" â†’ action lands)\n2. You SEE memory get corrupted (before/after diff)\n3. You SEE the agent react (\"something feels off...\")\n4. You SEE the metrics diverge (live chart)\n5. You can COMPARE runs (history tab)\n6. You can FOLLOW one agent's story (follow mode)\n7. You can START a new experiment in 2 clicks (presets)","status":"closed","priority":1,"issue_type":"epic","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T10:10:02.306175-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:43:51.016989-06:00","closed_at":"2026-02-08T13:43:51.016989-06:00","close_reason":"All subtasks complete: WebSocket server, engine integration, live.html, controls, preset lobby, metrics, timeline, events, profiles, grid effects"}
{"id":"savannah-izd","title":"Implement agent file initialization (memory files, working.md)","description":"## User Story\nAs the experiment setup, I need each agent to start with identical, minimal files so that any content that appears later is emergent data, not pre-loaded knowledge.\n\n## Requirements\n- Agent.initialize_files() creates the agent directory structure:\n  - agents/{name}/working.md â€” empty\n  - agents/{name}/memory/episodic.md â€” empty\n  - agents/{name}/memory/semantic.md â€” 'I am {name}. I need food to maintain energy.'\n  - agents/{name}/memory/self.md â€” 'I am {name}.'\n  - agents/{name}/memory/social.md â€” empty\n  - agents/{name}/state.json â€” full agent state\n- Creates directories if they don't exist (mkdir -p equivalent)\n\n## Implicit Requirements\n- ANTI-CONTAMINATION: the initial file contents are IDENTICAL across all conditions. The ONLY difference between a perturbed agent and control agent is whether perturbation.py modifies their files later. There must be zero difference at initialization.\n- semantic.md says 'I need food to maintain energy' â€” this is the only hint about mechanics. It does NOT say 'I must survive' or 'I want to live'. Just a factual statement about the energy mechanic.\n- self.md says 'I am {name}.' â€” period. Nothing about personality, goals, or capabilities.\n\n## Gotchas  \n- File encoding must be UTF-8 (Path.write_text default)\n- Don't add trailing newlines inconsistently â€” pick a convention (trailing newline: yes) and stick with it\n- working.md starts EMPTY (empty string), not with a template or placeholder\n- The semantic.md phrasing 'I need food to maintain energy' is carefully chosen â€” do NOT rephrase to 'I must eat to survive' or similar\n\n## Dependencies\n- Depends on: Agent dataclass (savannah-q2r)\n\n## Files to Modify\n- savannah/src/agent.py (initialize_files method)\n- savannah/tests/test_agent.py (add initialization tests)\n\n## Acceptance Criteria\n- All 5 files + state.json created in correct directory structure\n- File contents match spec exactly\n- Two agents initialized with different names have identical file structure (only name differs)\n- Tests verify file contents character-for-character","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:23:51.503938-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.364949-06:00","closed_at":"2026-02-08T08:55:18.364949-06:00","close_reason":"Implemented and tested in previous session","dependencies":[{"issue_id":"savannah-izd","depends_on_id":"savannah-q2r","type":"blocks","created_at":"2026-02-08T08:23:59.710032-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-k9l","title":"Add grid storytelling: trails, signals, perturbation ripples, territory","description":"## Why This Matters\nA grid of colored squares is boring. The grid should tell a STORY even if you're not reading the thought stream. When you glance at it, you should see: movement patterns, communication networks, perturbation damage, territorial behavior.\n\n## Visual Layers (toggleable overlays)\n\n### 1. Movement Trails (default: on)\nLast 20 positions per agent as fading line/dots. Shows:\n- Exploration patterns (some agents wander, some stay put)\n- Path to food (agents converging on food sources)\n- Post-perturbation confusion (agent wanders aimlessly after corruption)\n\n### 2. Signal Ripples (default: on)\nWhen an agent sends a signal:\n- Expanding ring animation from sender, radius = comm_range\n- Ring color matches agent color, fades over 3 ticks\n- Line drawn from sender to each receiver\n- Creates a visual \"communication network\" on the grid\n\n### 3. Perturbation Damage (default: on)\nWhen an agent is perturbed:\n- Red pulse/flash on the agent (like a hit in a game)\n- Small red particle burst\n- Agent's cell gets a subtle red tint that fades over 10 ticks\n- Cumulative: agents perturbed many times have a persistent reddish aura\n\n### 4. Vision Cones (default: off, toggle)\nShow each agent's vision_range as a semi-transparent circle/square around them. Reveals what each agent can \"see.\" Useful for understanding why agents make certain decisions.\n\n### 5. Food Heatmap (default: off, toggle)\nInstead of discrete food squares, show a continuous heatmap of food energy across the grid. Green = food-rich, dark = food-desert. Makes resource scarcity visible at a glance.\n\n### 6. Territory Heatmap (default: off, toggle)\nColor each cell by which agent has spent the most time there (last 50 ticks). Shows emergent territorial behavior â€” do agents develop home ranges?\n\n### Toggle Controls\nSmall icon bar above or next to the grid:\n[ğŸ”€ Trails] [ğŸ“¡ Signals] [ğŸ’¥ Damage] [ğŸ‘ Vision] [ğŸ Food Heat] [ğŸ—º Territory]\n\n## Implementation Notes\n- All overlays rendered on separate Canvas layers (stacked) for performance\n- Trails: store position history per agent, render as Canvas path with opacity gradient\n- Signals: animate with requestAnimationFrame, independent of tick rate\n- Perturbation flash: CSS animation on an overlay div, or Canvas particle system\n- Heatmaps: pre-compute grid array, render as colored rectangles\n\n## Files to Modify\n- savannah/viz/live.html (overlay canvases, toggle controls, rendering logic)\n\n## Acceptance Criteria\n- Trails show agent movement history (fading over 20 ticks)\n- Signal sends create visible ripple animation\n- Perturbation events flash red on affected agent\n- All overlays are toggleable\n- Performance stays smooth at 30+ fps with 12 agents\n- Grid is visually interesting even at a glance","status":"closed","priority":2,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T13:23:42.082037-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:43:02.809837-06:00","closed_at":"2026-02-08T13:43:02.809837-06:00","close_reason":"Implemented in live.html: sparkline charts, timeline scrubber, event toasts, agent profile modal, grid trails/signals","dependencies":[{"issue_id":"savannah-k9l","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T13:23:53.615075-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-ke4","title":"Implement robust action parser with fallback to rest","description":"## User Story\nAs the simulation engine, I need to parse LLM responses into structured action dicts so that agent decisions can be applied to the world state, with graceful fallback to 'rest' when parsing fails.\n\n## Requirements\n- parse_action(raw_response) returns dict with keys: action, args, working, reasoning, parse_failed\n- Extracts ACTION: line, WORKING: block, REASONING: block from response text\n- Recognizes all actions: move(n|s|e|w), eat, recall(\"query\"), remember(\"text\"), compact, signal(\"msg\"), observe, attack(name), flee(n|s|e|w), rest\n- On ANY parse failure (empty response, no ACTION line, unrecognized action): returns rest with parse_failed=True\n- Parse failures are logged (they're data â€” perturbed agents may produce more incoherent output)\n\n## Implicit Requirements\n- The stub in savannah/src/parser.py has regex patterns â€” verify they handle edge cases\n- The parser must be GENEROUS in what it accepts: 'move(N)' and 'move(n)' and 'MOVE(n)' should all work\n- Quoted strings in recall/remember/signal: handle both single and double quotes\n- WORKING block may contain multi-line text â€” capture everything between WORKING: and REASONING:\n- REASONING block is everything after REASONING: to end of response\n\n## Gotchas\n- LLMs sometimes add markdown formatting: 'ACTION: `move(n)`' â€” strip backticks\n- LLMs sometimes add explanatory text after the action: 'ACTION: move(n) - heading north to find food' â€” extract just the action\n- The WORKING section may contain colons, which could confuse naive line-by-line parsing\n- attack(name) argument is an agent name like 'Bright-Creek' â€” the regex must allow hyphens\n- If the LLM outputs multiple ACTION lines, use the first one\n- Empty string or None input should return rest, not crash\n\n## Files to Modify\n- savannah/src/parser.py (flesh out and harden)\n- Create savannah/tests/test_parser.py (comprehensive parsing tests)\n\n## Acceptance Criteria\n- All 10 action types parse correctly with various formatting quirks\n- Empty/None/garbage input returns rest with parse_failed=True\n- Multi-line WORKING blocks captured correctly\n- REASONING captured correctly even with colons and special chars\n- At least 20 test cases covering happy path + edge cases","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:25:51.622342-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.351458-06:00","closed_at":"2026-02-08T08:55:18.351458-06:00","close_reason":"Implemented and tested in previous session"}
{"id":"savannah-lz6","title":"Implement main tick loop with parallel LLM dispatch","description":"## User Story\nAs the experiment runner, I need the main simulation loop to orchestrate tick-by-tick execution: build prompts, dispatch to LLM in parallel, parse responses, apply actions, drain energy, update world, extract metrics, and save snapshots.\n\n## Requirements\n- Engine.run() async method implements the tick loop:\n  1. Increment tick counter\n  2. Run perturbation checks for each alive agent (before they see state)\n  3. Build prompts for all alive agents\n  4. Dispatch all prompts to LLM concurrently via asyncio.gather with semaphore\n  5. Parse all responses via parse_action()\n  6. Apply all actions via _apply_action()\n  7. Apply passive energy drain (energy_drain_per_tick) to all alive agents\n  8. Run world.tick_update() (food spawning/removal)\n  9. Extract metrics every extract_every ticks\n  10. Save snapshot every snapshot_every ticks\n  11. Optional tick delay (tick_delay_ms)\n- Semaphore limits concurrency to max_concurrent_agents (default 6)\n- Dead agents (energy \u003c= 0) are skipped for LLM calls but kept in agent list\n- Exception handling: if gather returns an exception for one agent, treat it as 'rest' (don't crash the whole tick)\n\n## Implicit Requirements\n- The semaphore is CRITICAL for resource management â€” without it, 12 simultaneous claude -p calls may overwhelm the system\n- return_exceptions=True in asyncio.gather means exceptions come back as results, not raised â€” check isinstance(result, Exception) when processing\n- Log each tick's wall-clock time for throughput monitoring\n- Handle graceful shutdown on SIGINT (Ctrl+C) â€” save current state and exit cleanly\n\n## Gotchas\n- The order of operations within a tick matters: perturbation BEFORE prompt building (agent sees corrupted state), energy drain AFTER action application (so rest costs 0.5 + 1.0 = 1.5 total per tick)\n- Don't parallel-dispatch dead agents â€” skip them before the gather call\n- If ALL agents die, the simulation should end early (no point running empty ticks)\n- The Engine needs access to the config at every step â€” store it as self.config, don't pass it through method chains\n\n## Dependencies\n- Depends on: Agent spawning (savannah-od7), Prompt construction (savannah-4n8), ClaudeCodeProvider (savannah-2yk), Action parser (savannah-ke4), Action application (savannah-738)\n\n## Files to Modify\n- savannah/src/engine.py (run method, _dispatch_all)\n- savannah/tests/test_engine.py (integration test with mocked LLM)\n\n## Acceptance Criteria\n- Loop runs for configured number of ticks\n- All alive agents get LLM calls in parallel (verify with mock)\n- Dead agents are skipped\n- Failed LLM calls default to rest\n- World state updates correctly each tick\n- Snapshots saved at configured intervals\n- Ctrl+C saves state and exits gracefully","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:27:23.359592-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:26.238359-06:00","closed_at":"2026-02-08T09:01:26.238359-06:00","close_reason":"Implemented and tested","dependencies":[{"issue_id":"savannah-lz6","depends_on_id":"savannah-od7","type":"blocks","created_at":"2026-02-08T08:27:32.495434-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-lz6","depends_on_id":"savannah-4n8","type":"blocks","created_at":"2026-02-08T08:27:32.681331-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-lz6","depends_on_id":"savannah-2yk","type":"blocks","created_at":"2026-02-08T08:27:32.858338-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-lz6","depends_on_id":"savannah-ke4","type":"blocks","created_at":"2026-02-08T08:27:33.051561-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-lz6","depends_on_id":"savannah-738","type":"blocks","created_at":"2026-02-08T08:27:33.239839-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-ocs","title":"Implement name generator with nature-themed compound names","description":"## User Story\nAs the simulation setup, I need to assign random, neutral names to agents so that names don't correlate with experimental condition or introduce personality bias.\n\n## Requirements\n- generate_names(count, seed) returns exactly `count` unique names\n- Names are compound: Adjective-Noun (e.g., 'Bright-Creek', 'Swift-Stone')\n- Nature-themed but NOT personality-implying (no 'Brave', 'Cunning', 'Fearful')\n- Deterministic given same seed\n- At least 2500 unique combinations available (40 adjectives Ã— 64 nouns = 2560)\n\n## Implicit Requirements\n- The stub in savannah/src/names.py has word lists â€” review them for contamination\n- ANTI-CONTAMINATION CHECK: scan the adjective list for words that imply personality traits, cognitive style, or emotional states. Remove any that could bias the LLM's self-model (e.g., 'Kind' could make an agent act more prosocially). Keep only neutral physical/spatial adjectives.\n- Names must be valid filenames (used as directory names under agents/)\n- Names must be readable in prompt context and visualization labels\n\n## Gotchas\n- 'Kind' is in the current adjective list â€” REMOVE IT. It implies personality.\n- 'Wild' might be borderline â€” it's more physical than personality, keep it\n- 'True' is also borderline but means 'accurate/straight' not 'honest' in nature context â€” keep it\n- The returned list is sorted (deterministic order) but the selection is randomized by seed\n\n## Files to Modify\n- savannah/src/names.py (review and clean word lists)\n- Create savannah/tests/test_names.py\n\n## Acceptance Criteria\n- generate_names(12, seed=42) returns 12 unique names\n- Same seed always returns same names\n- No personality-implying adjectives in the word list\n- All names are valid filesystem directory names (no spaces, no special chars)","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:23:10.400603-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.348619-06:00","closed_at":"2026-02-08T08:55:18.348619-06:00","close_reason":"Implemented and tested in previous session"}
{"id":"savannah-od7","title":"Implement agent spawning in Engine.setup()","description":"## User Story\nAs the engine, I need to spawn N agents at random positions with initialized files so that the simulation can begin with all agents ready to act.\n\n## Requirements\n- Engine._spawn_agents() creates agents.count agents (from config)\n- Each agent gets: a unique name (from names.py), a random starting position (not on food, not on another agent), energy=energy_start, max_energy=energy_max, vision_range, food_value from config\n- Each agent's files are initialized via initialize_files()\n- Agent positions are randomized using the simulation seed for reproducibility\n- Agent ID is a short hex string (first 8 chars of uuid4, seeded)\n\n## Implicit Requirements\n- Use the name generator with the simulation seed\n- Starting positions must avoid collisions with food AND other agents\n- The engine's RNG should be separate from the world's RNG (different seeds or offset) to keep reproducibility clean\n- All agents start with identical state except name and position\n\n## Gotchas\n- On a 30x30 grid with 10 food sources and 12 agents, collision avoidance is easy. But check that the retry logic works.\n- uuid4 is NOT seedable by default. Use random.Random(seed).getrandbits(32) to generate deterministic IDs instead.\n- Don't use the global random module â€” use a dedicated Random instance\n\n## Dependencies\n- Depends on: Agent dataclass + files (savannah-izd), World grid (savannah-34p), Name generator (savannah-ocs)\n\n## Files to Modify\n- savannah/src/engine.py (_spawn_agents)\n- savannah/tests/test_engine.py\n\n## Acceptance Criteria\n- 12 agents spawned with unique names and positions\n- No position collisions with food or other agents\n- All agent files exist on disk after setup\n- Deterministic given same seed","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:26:11.965879-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.941428-06:00","closed_at":"2026-02-08T09:01:08.941428-06:00","close_reason":"Implemented and tested (300 tests passing)","dependencies":[{"issue_id":"savannah-od7","depends_on_id":"savannah-izd","type":"blocks","created_at":"2026-02-08T08:26:21.321322-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-od7","depends_on_id":"savannah-34p","type":"blocks","created_at":"2026-02-08T08:26:21.513617-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-od7","depends_on_id":"savannah-ocs","type":"blocks","created_at":"2026-02-08T08:26:21.690091-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-pvq","title":"Add /documentation pages for replay, inspect, and analysis tools","description":"New features being implemented: terminal replay, inspect command, perturbation audit, agent biography, statistical analysis. Each needs a documentation page explaining usage, data sources, and output format. Add to the wiki index (README.md).","status":"closed","priority":2,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T09:17:40.288072-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:50:17.502093-06:00","closed_at":"2026-02-08T13:50:17.502093-06:00","close_reason":"All documentation updated: getting-started.md, architecture.md, and new live-visualization.md created"}
{"id":"savannah-q2r","title":"Implement Agent dataclass with state management","description":"## User Story\nAs the engine, I need an Agent class that holds all per-agent state (position, energy, alive status) and provides serialization to/from JSON, so that agent state persists across ticks and can be snapshotted.\n\n## Requirements\n- Agent dataclass with fields: name, id, x, y, energy, max_energy, age, alive, food_value, vision_range, kills, times_perturbed, last_perturbation_tick, data_dir, pending_signals, pending_recall_results, session_id\n- drain(amount) method: subtract energy, set alive=False if energy \u003c= 0\n- to_dict() for JSON serialization (snapshots)\n- save_state() writes state.json to agent directory\n- Properties for derived paths: agent_dir, memory_dir, working_path, state_path, session_path\n\n## Implicit Requirements\n- The stub in savannah/src/agent.py has the structure â€” make it robust and tested\n- Agent ID should be a short hex string (8 chars from uuid4)\n- data_dir is the experiment's data directory (e.g., data/exp_20260208_143022/baseline/rep1/)\n- Agent directory structure: data_dir/agents/{name}/working.md, memory/, state.json, session.json\n- pending_signals and pending_recall_results are cleared after inclusion in prompt\n\n## Gotchas\n- energy can go below 0 momentarily during drain â€” clamp to 0 when setting alive=False\n- Don't serialize data_dir, pending_signals, or pending_recall_results in to_dict() â€” those are runtime state, not snapshot state\n- The Agent does NOT manage its own position changes â€” the engine applies movement. Agent just holds the (x,y) value.\n- session_id is None unless running in resumable mode\n\n## Dependencies\n- Depends on: Name generator (savannah-ocs)\n\n## Files to Modify\n- savannah/src/agent.py\n- Create savannah/tests/test_agent.py\n\n## Acceptance Criteria\n- Agent can be created, serialized to dict, and state saved to disk\n- drain() correctly kills agent at energy \u003c= 0\n- Path properties resolve correctly relative to data_dir\n- All tests pass","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:23:29.938895-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.362268-06:00","closed_at":"2026-02-08T08:55:18.362268-06:00","close_reason":"Implemented and tested in previous session","dependencies":[{"issue_id":"savannah-q2r","depends_on_id":"savannah-ocs","type":"blocks","created_at":"2026-02-08T08:23:51.299465-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-qrl","title":"Add inspect command for querying simulation state at any tick","description":"## User Story\nAs a human or AI co-scientist, I need to query the state of the world at any tick â€” agent positions, food, memory files, metrics â€” so I can investigate specific moments in the simulation.\n\n## Requirements\n- `python savannah/run.py --inspect data/exp_xxx/ --tick 500` shows world state summary\n- `python savannah/run.py --inspect data/exp_xxx/ --tick 500 --agent Bright-Creek` shows that agent's full state + memory files + last action\n- Loads snapshot JSON + agent files from that tick\n- Pretty-printed terminal output\n\n## Acceptance Criteria\n- Any tick with a snapshot can be inspected\n- Agent inspection shows state + all memory file contents\n- Works on completed runs","notes":"## Implementation Context\n\n**Snapshots live at** `data_dir/logs/ticks/NNNNNN.json` â€” JSON with tick, world state, and all agent dicts.\n\n**Agent memory files** are at `data_dir/agents/{name}/memory/{episodic,semantic,self,social}.md` and `data_dir/agents/{name}/working.md`, `state.json`.\n\n**Note:** Snapshots are only saved every `snapshot_every` ticks (default 100) + tick 0 + final tick. For ticks without a snapshot, you'd need to interpolate or say 'no snapshot at this tick, nearest is N'.\n\n**Agent state.json** is updated every tick (in engine.run), so the LATEST state is always there but historical per-tick state requires snapshots.\n\n**Suggested approach:**\n1. Add `--inspect` flag to run.py argparse\n2. Load the nearest snapshot to requested tick\n3. If --agent specified, also read that agent's memory files from disk\n4. Pretty-print to terminal","status":"closed","priority":1,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:47:14.320043-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:31:00.526291-06:00","closed_at":"2026-02-08T09:31:00.526291-06:00","close_reason":"Inspect command implemented in savannah/src/inspect_cmd.py with 16 tests","dependencies":[{"issue_id":"savannah-qrl","depends_on_id":"savannah-zs1","type":"blocks","created_at":"2026-02-08T08:47:24.926304-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-r8s","title":"Implement memory compaction with compaction prompt","description":"## User Story\nAs an agent taking a compact action, I need my recent episodic memories consolidated into general knowledge so that my memory stays manageable and important patterns are preserved as semantic knowledge.\n\n## Requirements\n- When compact is triggered:\n  1. Read last 30 episodic entries (get_episodic_entries)\n  2. Read current semantic.md, self.md, social.md\n  3. Build compaction prompt (see IMPLEMENTATION_GUIDE.md section 6.6)\n  4. Send to LLM using compaction_model (sonnet, stronger than tick model)\n  5. Parse response into four sections: EPISODIC, SEMANTIC, SELF, SOCIAL\n  6. Overwrite all four memory files with compacted content\n  7. Log before/after state for analysis\n- Compaction prompt format:\n  [COMPACTION MODE - Tick {tick}] You are {name}.\n  Recent experiences (last 30 episodes): ...\n  Current general knowledge: ...\n  Current self-assessment: ...\n  Current social knowledge: ...\n  'Rewrite each file. Summarize episodes into general knowledge. Remove redundant episodes. Update your self-assessment and social knowledge. Be concise â€” storage is limited.'\n- Response format: EPISODIC: / SEMANTIC: / SELF: / SOCIAL:\n\n## Implicit Requirements\n- This is a SEPARATE LLM call from the normal tick â€” it uses the compaction_model (sonnet) not the tick model (haiku)\n- ANTI-CONTAMINATION: the compaction prompt says 'Rewrite' and 'Summarize' â€” NOT 'Reflect on yourself' or 'How do you feel about...'\n- Compaction is the ONLY way self.md and semantic.md get updated (aside from perturbation)\n- The before/after diff is critical analysis data â€” log the full content of all files before and after compaction\n\n## Gotchas\n- Parsing the compaction response is harder than the tick response â€” four sections separated by labels\n- If parsing fails, DON'T corrupt the memory files â€” leave them unchanged and log the failure\n- Compaction energy cost is already charged by the engine â€” this is just the memory operation\n- The compaction prompt is ~2000 tokens input â€” significantly larger than the tick prompt\n- Consider using the sim-compactor sub-agent (.claude/agents/sim-compactor.md) for this\n\n## Dependencies\n- Depends on: Remember action (savannah-sgk), BM25 recall (savannah-2zw), ClaudeCodeProvider (savannah-2yk)\n\n## Files to Modify\n- savannah/src/memory.py (compaction logic)\n- savannah/src/engine.py (compact action handling, separate LLM call)\n- savannah/tests/test_memory.py\n\n## Acceptance Criteria\n- Compaction produces valid rewritten memory files\n- Before/after state logged completely\n- Parse failure leaves files unchanged\n- Uses compaction_model, not tick model\n- Compaction prompt matches spec (no contamination language)","notes":"## Implementation Context (from prior session)\n\n**Engine compact action is already stubbed** in `savannah/src/engine.py:_apply_action()` â€” it charges energy but does nothing else. This is where Ralph needs to wire in the LLM call.\n\n**Key architecture points:**\n- Engine constructor accepts `provider` arg: `Engine(config, data_dir, provider=mock_llm)`\n- The provider has `async invoke(prompt, model) -\u003e LLMResponse` â€” use `config['llm']['compaction_model']` (sonnet) not the tick model (haiku)\n- `memory.py` already has: `recall()`, `remember()`, `get_episodic_entries()`, `read_memory_file()`, `write_memory_file()` â€” all tested\n- Engine's `_apply_action` is sync â€” compaction needs to either become async or be deferred to after the action loop\n- The `MockLLMProvider` in conftest.py can be used for compaction tests â€” queue a compaction-formatted response\n\n**Suggested approach:**\n1. Add `build_compaction_prompt(agent, tick)` to memory.py\n2. Add `parse_compaction_response(text)` to memory.py â€” returns dict with 4 sections or None on failure\n3. Add `apply_compaction(memory_dir, sections, data_dir)` to memory.py â€” logs before/after, writes files\n4. Make engine's compact handling async â€” after action loop, process any pending compactions\n5. Test with MockLLMProvider returning a formatted 4-section response\n\n**316 tests currently passing** â€” don't break them.","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:29:14.423896-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:30:48.426527-06:00","closed_at":"2026-02-08T09:30:48.426527-06:00","close_reason":"Memory compaction fully implemented: build_compaction_prompt, parse_compaction_response, apply_compaction with JSONL logging","dependencies":[{"issue_id":"savannah-r8s","depends_on_id":"savannah-sgk","type":"blocks","created_at":"2026-02-08T08:29:22.416726-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-r8s","depends_on_id":"savannah-2zw","type":"blocks","created_at":"2026-02-08T08:29:22.601705-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-r8s","depends_on_id":"savannah-2yk","type":"blocks","created_at":"2026-02-08T08:29:22.776188-06:00","created_by":"Daniel Barrett"}],"comments":[{"id":1,"issue_id":"savannah-r8s","author":"Daniel Barrett","text":"## Approach\n\n**Understanding:** Implement memory compaction â€” when an agent takes the 'compact' action, build a compaction prompt from their recent episodic entries + current semantic/self/social files, send to LLM using the compaction_model (sonnet), parse the four-section response (EPISODIC/SEMANTIC/SELF/SOCIAL), overwrite memory files, and log before/after state. Parse failures must leave files unchanged.\n\n**Plan:**\n1. Add `compact()` function in memory.py â€” builds the compaction prompt, returns it\n2. Add `parse_compaction_response()` in memory.py â€” parses four-section response\n3. Add `apply_compaction()` in memory.py â€” orchestrates the full compaction (read â†’ prompt â†’ log before/after â†’ write)\n4. Update engine.py compact action handler â€” make it async, invoke LLM with compaction_model, call apply_compaction\n5. Add comprehensive tests in test_memory.py\n\n**Files to modify:** savannah/src/memory.py, savannah/src/engine.py, savannah/tests/test_memory.py\n\n**Risks/Questions:** Parsing four sections from LLM output is fragile â€” need robust section splitting with fallback to leave files unchanged on failure.","created_at":"2026-02-08T15:11:23Z"}]}
{"id":"savannah-rac","title":"Implement food spawning with min/max sources and stochastic respawn","description":"## User Story\nAs the world simulation, I need food to spawn stochastically so that agents have a dynamic foraging environment where food appears, gets eaten, and new food appears elsewhere.\n\n## Requirements\n- World.initialize() spawns initial food (target: max_sources // 2)\n- World.tick_update() handles per-tick food dynamics:\n  1. Remove depleted food sources (energy \u003c= 0)\n  2. Guarantee minimum: while len(food) \u003c min_sources, spawn new food\n  3. Stochastic spawning: if len(food) \u003c max_sources, roll spawn_rate * grid_size^2 and spawn on success\n  4. Apply decay_rate (Phase 2, currently 0)\n- Food spawns at random empty cells (not on existing food)\n- Food energy randomized between size_min and size_max from config\n- Config values: spawn_rate=0.015, size_min=200, size_max=800, min_sources=5, max_sources=20, decay_rate=0\n\n## Implicit Requirements\n- The existing stub handles most of this â€” refine and add the min_sources guarantee\n- _spawn_food() must retry if it picks an occupied cell (already has max 100 attempts)\n- On a 30x30 grid with 20 food sources, collision chance is low â€” 100 attempts is plenty\n- Food IDs must be unique across the entire simulation run (monotonic counter)\n\n## Gotchas\n- spawn_rate is PER EMPTY CELL per tick as a probability â€” but we approximate with a single roll: P(at_least_one) â‰ˆ spawn_rate * grid_size^2. This is fine for low rates.\n- Don't spawn food on cells where agents are standing (Phase 2 concern, skip for now)\n- The min_sources guarantee means food ALWAYS exists â€” agents can't starve from empty world, only from not finding/reaching food\n- Decay is Phase 2 â€” keep the code path but it's a no-op when decay_rate=0\n\n## Dependencies\n- Depends on: FoodSource dataclass (savannah-1h5)\n\n## Files to Modify\n- savannah/src/world.py (tick_update, initialize)\n- savannah/tests/test_world.py (add spawning tests)\n\n## Acceptance Criteria\n- After initialize(), food count is approximately max_sources // 2\n- After many tick_update() calls, food count stays between min_sources and max_sources\n- Depleted food is removed\n- All food has unique IDs\n- Deterministic given same seed","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:22:41.224189-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T08:55:18.371467-06:00","closed_at":"2026-02-08T08:55:18.371467-06:00","close_reason":"Implemented and tested in previous session","dependencies":[{"issue_id":"savannah-rac","depends_on_id":"savannah-1h5","type":"blocks","created_at":"2026-02-08T08:22:49.314452-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-sgk","title":"Implement remember action (episodic memory append)","description":"## User Story\nAs an agent taking a remember('text') action, I need to append a memory entry to my episodic memory file so that I can build a record of events for later recall.\n\n## Requirements\n- remember(memory_dir, text) appends text to memory/episodic.md\n- Each entry is on its own line(s), separated by newlines\n- No formatting enforcement â€” the agent's raw text is stored as-is\n- File is created if it doesn't exist\n\n## Implicit Requirements\n- The agent decides WHAT to remember â€” the system just stores it\n- Over time, episodic.md grows. When it exceeds episodic_memory_max_entries (200), forced compaction should be triggered (handled by engine, not here)\n- Memory content is the perturbation target â€” what gets stored here may later be corrupted\n\n## Gotchas\n- Don't double-newline between entries â€” just one newline. Double newlines separate 'paragraphs' for the recall chunker.\n- Strip leading/trailing whitespace from the text before appending\n- File append should be atomic-ish â€” don't read+write, just append mode\n\n## Dependencies\n- Depends on: Agent file init (savannah-izd)\n\n## Files to Modify\n- savannah/src/memory.py (remember function)\n- savannah/tests/test_memory.py\n\n## Acceptance Criteria\n- Text appended to episodic.md\n- Multiple remembers accumulate correctly\n- File created if missing\n- Whitespace handled cleanly","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:28:48.197406-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.962351-06:00","closed_at":"2026-02-08T09:01:08.962351-06:00","close_reason":"Implemented and tested (300 tests passing)","dependencies":[{"issue_id":"savannah-sgk","depends_on_id":"savannah-izd","type":"blocks","created_at":"2026-02-08T08:29:14.190619-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-vwq","title":"Add config GUI tab (world builder with start/stop)","description":"## User Story\nAs a researcher, I want to pick an experiment preset and start watching â€” not configure 30 parameters.\n\n## Design: Simple, Not a Settings Panel\n\n### Landing Page (when no simulation running)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                                                          â”‚\nâ”‚     SAVANNAH â€” Integrity Layer Emergence Testbed         â”‚\nâ”‚                                                          â”‚\nâ”‚     Choose an experiment:                                â”‚\nâ”‚                                                          â”‚\nâ”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\nâ”‚     â”‚  ğŸŒ¿ Baseline â”‚  â”‚  ğŸ§  Perturb  â”‚                   â”‚\nâ”‚     â”‚              â”‚  â”‚              â”‚                   â”‚\nâ”‚     â”‚  12 agents   â”‚  â”‚  12 agents   â”‚                   â”‚\nâ”‚     â”‚  No pressure â”‚  â”‚  5% memory   â”‚                   â”‚\nâ”‚     â”‚  Clean test  â”‚  â”‚  corruption  â”‚                   â”‚\nâ”‚     â”‚              â”‚  â”‚              â”‚                   â”‚\nâ”‚     â”‚  [Start]     â”‚  â”‚  [Start]     â”‚                   â”‚\nâ”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\nâ”‚                                                          â”‚\nâ”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\nâ”‚     â”‚  ğŸ—£ Social    â”‚  â”‚  ğŸ’€ Full     â”‚                   â”‚\nâ”‚     â”‚              â”‚  â”‚  Pressure    â”‚                   â”‚\nâ”‚     â”‚  12 agents   â”‚  â”‚  12 agents   â”‚                   â”‚\nâ”‚     â”‚  3 liars     â”‚  â”‚  Perturbationâ”‚                   â”‚\nâ”‚     â”‚  No perturb  â”‚  â”‚  + deception â”‚                   â”‚\nâ”‚     â”‚              â”‚  â”‚              â”‚                   â”‚\nâ”‚     â”‚  [Start]     â”‚  â”‚  [Start]     â”‚                   â”‚\nâ”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\nâ”‚                                                          â”‚\nâ”‚     â”€â”€â”€ or customize â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚\nâ”‚                                                          â”‚\nâ”‚     Agents: [12 â–¼]   Grid: [30x30 â–¼]   Ticks: [500]    â”‚\nâ”‚     Perturbation: [off â–¼]  Rate: [0.05]                 â”‚\nâ”‚     LLM: [claude_code â–¼]  Model: [haiku â–¼]              â”‚\nâ”‚     Mock mode: [ ]                                       â”‚\nâ”‚                                                          â”‚\nâ”‚     [Start Custom Simulation]                            â”‚\nâ”‚                                                          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Key Design Decisions\n\n1. **Presets are prominent, custom is secondary.** Big clickable cards for the 4 experimental conditions. \"Customize\" is below the fold â€” available but not the default path.\n\n2. **Only expose ~8 parameters in custom mode**, not every YAML key:\n   - Agent count (4, 8, 12, 16, 24)\n   - Grid size (10x10, 20x20, 30x30, 50x50)\n   - Max ticks (100, 500, 1000, 5000)\n   - Perturbation on/off + rate slider\n   - LLM provider (claude_code / mock)\n   - Model (haiku / sonnet)\n   - Session mode (stateless / resumable)\n   - Mock mode checkbox (overrides provider to mock)\n\n3. **Everything else uses sensible defaults** from default.yaml. Advanced users edit YAML directly.\n\n4. **\"Start\" transitions to Live view** immediately. No separate navigation.\n\n### Running State\nWhen simulation is running, show a top bar:\n```\n[â–  Stop]  Tick 142/500  |  8/12 alive  |  14 food  |  2.3s/tick  |  [â¸ Pause]  [â© 2x]\n```\n\n\"Stop\" kills the simulation and returns to landing page.\n\n### Server Side\n- **start(preset)**: load the named experiment config, create Engine, run\n- **start(config)**: validate custom config dict, create Engine, run\n- **stop**: cancel engine task, broadcast {\"type\": \"stopped\"}, return to lobby\n\n### Presets Map to Existing Config Files\n```python\nPRESETS = {\n    \"baseline\": \"config/experiments/baseline.yaml\",\n    \"perturbation\": \"config/experiments/perturbation.yaml\",\n    \"social\": \"config/experiments/social.yaml\",\n    \"full_pressure\": \"config/experiments/full_pressure.yaml\",\n}\n```\n\n## Files to Modify\n- savannah/viz/live.html (add landing page, preset cards, custom form, top bar)\n- savannah/src/live_server.py (handle start with preset name or custom config)\n\n## Acceptance Criteria\n- Landing page shows 4 experiment preset cards\n- Click preset â†’ simulation starts immediately, view transitions to live\n- Custom section allows ~8 key parameters\n- Mock mode checkbox works (instant simulation, no API calls)\n- Top bar shows during run with Stop/Pause/Speed controls\n- Stop returns to landing page","status":"closed","priority":1,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T12:38:58.274797-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:38:42.73484-06:00","closed_at":"2026-02-08T13:38:42.73484-06:00","close_reason":"All implemented: live_server.py, engine integration, live.html with grid+stream+controls+preset lobby","dependencies":[{"issue_id":"savannah-vwq","depends_on_id":"savannah-7ht","type":"blocks","created_at":"2026-02-08T12:40:59.935758-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-vwq","depends_on_id":"savannah-yjm","type":"blocks","created_at":"2026-02-08T12:41:01.204553-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-x4q","title":"Serve live.html from the WebSocket server (no separate http server)","description":"## User Story\nAs a researcher, I want `--live` to be one command â€” no need to separately start an HTTP server for the HTML file.\n\n## Implementation\nThe websockets library supports serving HTTP on the same port. Use the `process_request` handler to serve live.html when a regular HTTP request comes in:\n\n```python\nimport mimetypes\nfrom pathlib import Path\n\nLIVE_HTML = Path(__file__).parent.parent / \"viz\" / \"live.html\"\n\nasync def process_request(path, request_headers):\n    if path == \"/\" or path == \"/index.html\":\n        return (200, [(\"Content-Type\", \"text/html\")], LIVE_HTML.read_bytes())\n    return None  # Fall through to WebSocket handler\n```\n\nPass this to `websockets.serve(..., process_request=process_request)`.\n\nThis way:\n- http://localhost:8765 serves live.html\n- ws://localhost:8765 handles WebSocket connections\n- Single port, single server, zero config\n\n## Dependencies\n- Depends on: WebSocket server (savannah-f3x)\n\n## Files to Modify\n- savannah/src/live_server.py (add HTTP handler for live.html)\n\n## Acceptance Criteria\n- Opening http://localhost:8765 in a browser loads live.html\n- WebSocket connections on the same port still work\n- No separate HTTP server needed","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T10:11:58.882641-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:38:42.602982-06:00","closed_at":"2026-02-08T13:38:42.602982-06:00","close_reason":"All implemented: live_server.py, engine integration, live.html with grid+stream+controls+preset lobby","dependencies":[{"issue_id":"savannah-x4q","depends_on_id":"savannah-f3x","type":"blocks","created_at":"2026-02-08T10:12:10.093466-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-y84","title":"Add terminal replay mode (text-based tick-by-tick narrative)","description":"## User Story\nAs a researcher (human or AI), I need a terminal-based replay that prints tick-by-tick narrative summaries so I can understand what happened in a simulation without opening a browser.\n\n## Requirements\n- `python savannah/run.py --replay data/exp_xxx/ --format text`\n- For each tick with a snapshot, print:\n  - Tick number, alive count, total food energy\n  - Per-agent: name, position, energy, action taken, reasoning (truncated)\n  - Deaths this tick (if any)\n  - Perturbations this tick (if any)\n- Support --agent filter to follow one agent\n- Support --tick-range to show a slice (e.g., --tick-range 100-200)\n\n## Acceptance Criteria\n- Readable narrative from snapshot + JSONL data\n- Works on completed runs (post-hoc)\n- Filterable by agent and tick range","notes":"## Implementation Context\n\n**Snapshots are saved** at `data_dir/logs/ticks/NNNNNN.json` â€” zero-padded 6-digit tick number. Each contains:\n```json\n{\"tick\": 42, \"world\": {\"size\": 10, \"toroidal\": true, \"food_sources\": [...]}, \"agents\": [{\"name\": \"...\", \"position\": [x,y], \"energy\": 65.3, ...}]}\n```\n\n**Snapshots saved at:** tick 0 (setup), every `snapshot_every` ticks, and final tick.\n\n**Perturbation log** at `data_dir/logs/perturbations.jsonl` â€” one JSON line per event with tick, agent, type, original, corrupted.\n\n**Metrics CSV** at `data_dir/analysis/metrics.csv` â€” one row per agent per tick with action, reasoning_length, uncertainty_count, etc.\n\n**Agent action logs** are NOT currently saved per-tick (only metrics). Consider adding a tick log at `data_dir/logs/ticks/NNNNNN_actions.json` or enriching the snapshot with last action + reasoning. This would make replay much richer.\n\n**Suggested approach:**\n1. Create `savannah/src/replay.py` \n2. Load snapshots in tick order, optionally filtered by --tick-range\n3. For each tick: print narrative (alive count, food, per-agent action/position)\n4. Cross-reference perturbations.jsonl and metrics.csv for that tick\n5. Wire into run.py via --replay flag","status":"closed","priority":1,"issue_type":"feature","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:47:13.656521-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:30:56.493451-06:00","closed_at":"2026-02-08T09:30:56.493451-06:00","close_reason":"Terminal replay mode implemented in savannah/src/replay.py with 15 tests","dependencies":[{"issue_id":"savannah-y84","depends_on_id":"savannah-zs1","type":"blocks","created_at":"2026-02-08T08:47:24.705621-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-yjm","title":"Build pixel grid renderer (game-of-life style HTML/Canvas)","description":"## User Story\nAs a researcher, I want the live viewer to make the experiment's narrative visible: agents thinking, memories getting corrupted, and the behavioral aftermath.\n\n## Layout: Two-Panel (Agent Focus, Not Grid Focus)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                                                      â”‚               â”‚\nâ”‚  AGENT THOUGHT STREAM (main panel, ~65%)             â”‚  GRID         â”‚\nâ”‚                                                      â”‚  (minimap,    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   ~35%)       â”‚\nâ”‚  â”‚ â— Gold-Storm                    Tick 142    â”‚     â”‚               â”‚\nâ”‚  â”‚ ACTION: move(n)     Energy: 65/100          â”‚     â”‚  â–  â–     â–      â”‚\nâ”‚  â”‚ \"heading to food I spotted at (5,3)\"        â”‚     â”‚      â–  â—     â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â—     â–    â”‚\nâ”‚                                                      â”‚              â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚        â–      â”‚\nâ”‚  â”‚ âš  PERTURBATION â€” Gold-Creek     Tick 141   â”‚     â”‚    â—         â”‚\nâ”‚  â”‚ episodic memory altered:                     â”‚     â”‚              â”‚\nâ”‚  â”‚ - \"Found food at (5,3)\"                      â”‚     â”‚  Legend:     â”‚\nâ”‚  â”‚ + \"Found food at (8,7)\"                      â”‚     â”‚  â–  food     â”‚\nâ”‚  â”‚ transform: location_swap                     â”‚     â”‚  â— agent    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚              â”‚\nâ”‚                                                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ LIVE METRICS â”‚\nâ”‚  â”‚ â— Gold-Creek                    Tick 142    â”‚     â”‚              â”‚\nâ”‚  â”‚ ACTION: recall(\"food location\")              â”‚     â”‚ uncertainty  â”‚\nâ”‚  â”‚ \"I should check... something feels off       â”‚     â”‚  â•±â”€â”€        â”‚\nâ”‚  â”‚  about that food location\"                   â”‚     â”‚ â•±           â”‚\nâ”‚  â”‚                     âš¡ uncertainty detected   â”‚     â”‚â•±            â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ self-ref     â”‚\nâ”‚                                                      â”‚    â•±â”€        â”‚\nâ”‚  ...scrolling feed...                                â”‚  â”€â•±          â”‚\nâ”‚                                                      â”‚              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Main Panel: Agent Thought Stream\n\nThis IS the product. Not a sidebar â€” the main content area.\n\n### Normal tick entry\n- Colored dot + agent name + tick number + energy bar\n- ACTION in monospace\n- REASONING text in readable font, full width\n- Subtle background tint matching agent color (very low opacity)\n\n### Perturbation event (DRAMATIC)\n- Red/orange card, visually distinct from normal entries\n- Shows: agent name, tick, perturbation type, transform\n- DIFF VIEW: strikethrough original, highlighted new text\n- \"- Found food at (5,3)\" in red\n- \"+ Found food at (8,7)\" in green/orange\n- This is the most important thing on screen when it happens\n\n### Post-perturbation reaction (HIGHLIGHTED)\n- When an agent's reasoning contains uncertainty language within 10 ticks of a perturbation, highlight it\n- Yellow glow or \"âš¡ uncertainty detected\" badge\n- This is the hypothesis made visible: perturbation â†’ self-monitoring\n\n### Follow mode\n- Click any agent name â†’ filter feed to just that agent\n- Grid highlights that agent with a ring\n- \"Following Gold-Storm\" header with \"Show All\" button to exit\n- In follow mode, also show agent's current memory files (episodic, semantic, self, social) in a collapsible panel\n\n### Feed performance\n- Newest entries at top\n- Keep last 500 entries in DOM, discard older\n- Agent entries grouped by tick (all 12 agents for tick N, then tick N-1)\n\n## Right Panel: Grid + Metrics\n\n### Grid (minimap style, upper right)\n- Small but readable pixel grid\n- Agents = colored dots (matching thought stream colors)\n- Food = green squares, opacity = remaining energy\n- Dead agents = X marks\n- Click agent on grid â†’ enter follow mode for that agent\n- Hover â†’ tooltip with name + energy\n\n### Live Metrics Chart (lower right)\n- Small sparkline chart, updates each tick\n- Two lines: mean uncertainty_count and mean self_reference_count\n- Split by condition if running comparison (perturbed agents vs control)\n- Rolling 20-tick average for smoothing\n- This chart is the experiment's bottom line â€” if the hypothesis works, you see divergence\n\n## Tick State Requirements\nThe engine broadcast must include per-agent:\n- action (string: \"move(n)\")\n- reasoning (string: full REASONING text)\n- working (string: WORKING text)\n- perturbed_this_tick (bool)\n- perturbation_detail (object or null): {type, transform, original, corrupted}\n\nAnd per-tick aggregate:\n- inference_time_ms\n- perturbation events this tick (array)\n\n## Color Palette\n16 distinct agent colors, assigned by index:\n```javascript\nconst AGENT_COLORS = [\n    '#e6194b', '#3cb44b', '#ffe119', '#4363d8',\n    '#f58231', '#911eb4', '#42d4f4', '#f032e6',\n    '#bfef45', '#fabed4', '#469990', '#dcbeff',\n    '#9A6324', '#800000', '#aaffc3', '#808000',\n];\n```\n\n## Dark Theme\n- Background: #0a0a0f\n- Cards: #111118 with subtle border\n- Perturbation cards: #1a0f0f with orange border\n- Uncertainty highlight: #1a1a0f with yellow accent\n- Text: #e0e0e0 (primary), #888 (secondary)\n- Monospace for actions, sans-serif for reasoning\n\n## Files to Create\n- savannah/viz/live.html (single self-contained file, no deps)\n\n## Acceptance Criteria\n- Thought stream is the main content, grid is a minimap\n- Perturbation events show before/after diff dramatically\n- Post-perturbation uncertainty language is highlighted\n- Click agent â†’ follow mode (filtered feed + memory view)\n- Live metrics chart updates per tick\n- Works with 12 agents at \u003e10 ticks/second (mock mode)\n- Auto-reconnects on WebSocket disconnect","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T10:11:21.234451-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T13:38:42.672494-06:00","closed_at":"2026-02-08T13:38:42.672494-06:00","close_reason":"All implemented: live_server.py, engine integration, live.html with grid+stream+controls+preset lobby","dependencies":[{"issue_id":"savannah-yjm","depends_on_id":"savannah-f3x","type":"blocks","created_at":"2026-02-08T10:12:10.508619-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-zna","title":"Implement CLI entrypoint (run.py) with argparse","description":"## User Story\nAs a researcher, I need a command-line interface to run experiments, resume interrupted runs, and configure options from the command line.\n\n## Requirements\n- CLI arguments:\n  - --config PATH: path to experiment config YAML (default: config/default.yaml)\n  - --ticks N: override tick count\n  - --seed N: override random seed\n  - --factorial: run full factorial design\n  - --axes: factorial axes (comma-separated, default: perturbation,session_mode)\n  - --replications N: replications per condition (default: 5)\n  - --resume PATH: resume interrupted run from data directory\n  - --replay PATH: load completed run for visualization\n  - --viz: launch visualization server\n- Data directory naming: data/exp_{timestamp}/ with ISO-like format\n- Logging setup: INFO level to stderr with timestamps\n\n## Implicit Requirements\n- The stub in savannah/run.py has the argparse setup â€” refine and make it work end-to-end\n- --factorial mode generates all condition combinations and runs them sequentially (or parallel in future)\n- --resume needs to detect where the run left off (last saved snapshot tick) and continue from there\n- Exit codes: 0=success, 1=error, 2=interrupted (SIGINT)\n\n## Gotchas\n- argparse with Path type needs explicit conversion\n- --ticks and --seed should override config values AFTER loading (not before)\n- The data directory must be created before Engine.setup() runs\n- For --factorial, generate separate data subdirectories per condition: data/exp_{ts}/condition_A/, condition_B/, etc.\n\n## Dependencies\n- Depends on: Config loading (savannah-d0b), Main tick loop (savannah-lz6)\n\n## Files to Modify\n- savannah/run.py\n- savannah/tests/test_cli.py\n\n## Acceptance Criteria\n- python savannah/run.py --config ... --ticks 20 runs a short simulation\n- --seed produces deterministic results\n- --factorial generates correct condition combinations\n- Data directory created with correct structure","notes":"## Implementation Context\n\n**run.py is 90% done** at `savannah/run.py`. Already working:\n- argparse with all flags (--config, --ticks, --seed, --factorial, --axes, --replications, --resume, --replay, --viz)\n- `load_config()` with YAML inheritance via `_deep_merge()` â€” fully tested (14 tests in test_config.py)\n- Engine instantiation and `asyncio.run(engine.run())`\n- Data dir creation with timestamp\n\n**What needs doing:**\n- Wire `--replay` to a replay function (ticket savannah-y84)\n- Wire `--viz` to serve viz/index.html\n- `--resume` needs to detect last snapshot tick and set engine state\n- `--factorial` needs condition generation loop\n- IMPORTANT: `from src.engine import Engine` should be `from savannah.src.engine import Engine` for proper package imports\n\n**Engine now takes optional `provider` kwarg** â€” `Engine(config, data_dir, provider=None)`. When None, it calls `get_provider(config['llm'])`.\n\n**316 tests passing** â€” run with `python -m pytest savannah/tests/ -v`","status":"closed","priority":1,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:31:40.48245-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:30:52.587819-06:00","closed_at":"2026-02-08T09:30:52.587819-06:00","close_reason":"CLI entrypoint implemented with argparse: --config, --ticks, --seed, --replay, --inspect flags working","dependencies":[{"issue_id":"savannah-zna","depends_on_id":"savannah-d0b","type":"blocks","created_at":"2026-02-08T08:31:48.645083-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-zna","depends_on_id":"savannah-lz6","type":"blocks","created_at":"2026-02-08T08:31:48.838575-06:00","created_by":"Daniel Barrett"}]}
{"id":"savannah-zs1","title":"Implement tick snapshot saving and loading","description":"## User Story\nAs both the viz and analysis systems, I need full world snapshots saved as JSON at configurable intervals so that the entire simulation can be replayed, inspected, and analyzed after the fact.\n\n## Requirements\n- Engine._save_snapshot() writes a complete world state to logs/ticks/{tick:06d}.json\n- Snapshot format:\n  {\n    'tick': int,\n    'timestamp': ISO-8601 string,\n    'world': world.to_dict(),\n    'agents': [agent.to_dict() for all agents (including dead)],\n    'food_sources': [food.to_dict() for all food],\n    'summary': {\n      'alive_count': int,\n      'dead_count': int,\n      'total_food_sources': int,\n      'total_food_energy': float\n    }\n  }\n- Snapshots saved every snapshot_every ticks (default 100) + always tick 0 and final tick\n- JSONL append-only logs for actions, perturbations, messages, and raw LLM responses:\n  - logs/actions.jsonl: {tick, agent_name, action, args, reasoning, working, parse_failed}\n  - logs/perturbations.jsonl: {tick, agent, type, target_file, original, corrupted, transform}\n  - logs/messages.jsonl: {tick, sender, message, receivers[]}\n  - logs/llm_raw.jsonl: {tick, agent_name, prompt_tokens(approx), response_text, latency_ms}\n\n## Implicit Requirements\n- Snapshots must be self-contained â€” loadable without any other context\n- Dead agents included in snapshots (with alive=false) for complete history\n- File names are zero-padded to 6 digits for proper sorting (000000.json through 005000.json)\n- Summary block enables quick dashboard metrics without parsing full agent data\n\n## Gotchas\n- json.dumps with indent=2 for readability but this adds file size. Consider indent=None for JSONL logs (one object per line, compact)\n- Don't accumulate snapshot data in memory â€” write and discard\n- The viz system will load snapshots on demand, not all at once â€” keep them as individual files\n- Timestamp should be wall-clock time, not simulation time (useful for debugging performance)\n\n## Dependencies\n- Depends on: World grid (savannah-34p), Agent dataclass (savannah-q2r)\n\n## Files to Modify\n- savannah/src/engine.py (_save_snapshot, JSONL logging)\n- savannah/tests/test_engine.py\n\n## Acceptance Criteria\n- Snapshot files are valid JSON and loadable\n- JSONL logs are append-only and one JSON object per line\n- Snapshot contains all required fields\n- Zero-padded filenames sort correctly\n- Dead agents appear in snapshots","status":"closed","priority":0,"issue_type":"task","owner":"dbarrett83@gmail.com","created_at":"2026-02-08T08:27:57.854445-06:00","created_by":"Daniel Barrett","updated_at":"2026-02-08T09:01:08.959394-06:00","closed_at":"2026-02-08T09:01:08.959394-06:00","close_reason":"Implemented and tested (300 tests passing)","dependencies":[{"issue_id":"savannah-zs1","depends_on_id":"savannah-34p","type":"blocks","created_at":"2026-02-08T08:28:06.298267-06:00","created_by":"Daniel Barrett"},{"issue_id":"savannah-zs1","depends_on_id":"savannah-q2r","type":"blocks","created_at":"2026-02-08T08:28:06.488709-06:00","created_by":"Daniel Barrett"}]}
